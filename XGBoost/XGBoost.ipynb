{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "XGBoost Accuracy: 88.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets,svm\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = datasets.load_iris()\n",
    "X_train = iris.data[:, :2]  # we only take the first two features.\n",
    "y_train = iris.target\n",
    "\n",
    "train_X = iris.data[:, :2]  # we only take the first two features.\n",
    "train_Y = iris.target\n",
    "\n",
    "test_X = iris.data[:, :2]  # we only take the first two features.\n",
    "test_Y = iris.target\n",
    "\n",
    "### first xgboost\n",
    "xgm = xgb.XGBClassifier()\n",
    "xgm.fit(X_train, y_train)\n",
    "y_pred = xgm.predict(X_train)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_train, predictions)\n",
    "print(xgm)\n",
    "print(\"XGBoost Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "Y = iris.target\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "need to call fit beforehand",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-78a7f2fc937e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy: %.2f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit)\u001b[0m\n\u001b[0;32m    555\u001b[0m         \"\"\"\n\u001b[0;32m    556\u001b[0m         \u001b[0mtest_dmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         class_probs = self.get_booster().predict(test_dmatrix,\n\u001b[0m\u001b[0;32m    558\u001b[0m                                                  \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m                                                  ntree_limit=ntree_limit)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mget_booster\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \"\"\"\n\u001b[0;32m    178\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Booster\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'need to call fit beforehand'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Booster\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: need to call fit beforehand"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEWCAYAAACOv5f1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xea100f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "model.fit(X_train, y_train)\n",
    "plot_importance(model)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### second xgboost\n",
    "\n",
    "xg_train = xgb.DMatrix( train_X, label=train_Y)\n",
    "xg_test = xgb.DMatrix(test_X, label=test_Y)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 3\n",
    "param['silent'] = True\n",
    "param['nthread'] = -1\n",
    "param['num_class'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[1]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[2]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[3]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[4]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[5]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[6]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[7]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[8]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[9]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[10]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[11]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[12]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[13]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[14]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[15]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[16]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[17]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[18]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[19]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[20]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[21]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[22]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[23]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[24]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[25]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[26]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[27]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[28]\ttrain-merror:0.166667\ttest-merror:0.166667\n",
      "[29]\ttrain-merror:0.166667\ttest-merror:0.166667\n",
      "[30]\ttrain-merror:0.166667\ttest-merror:0.166667\n",
      "[31]\ttrain-merror:0.166667\ttest-merror:0.166667\n",
      "[32]\ttrain-merror:0.166667\ttest-merror:0.166667\n",
      "[33]\ttrain-merror:0.166667\ttest-merror:0.166667\n",
      "[34]\ttrain-merror:0.166667\ttest-merror:0.166667\n",
      "[35]\ttrain-merror:0.16\ttest-merror:0.16\n",
      "[36]\ttrain-merror:0.153333\ttest-merror:0.153333\n",
      "[37]\ttrain-merror:0.153333\ttest-merror:0.153333\n",
      "[38]\ttrain-merror:0.153333\ttest-merror:0.153333\n",
      "[39]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[40]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[41]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[42]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[43]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[44]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[45]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[46]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[47]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[48]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[49]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[50]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[51]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[52]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[53]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[54]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[55]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[56]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[57]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[58]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[59]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[60]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[61]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[62]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[63]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[64]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[65]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[66]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[67]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[68]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[69]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[70]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[71]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[72]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[73]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[74]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[75]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[76]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[77]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[78]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[79]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[80]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[81]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[82]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[83]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[84]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[85]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[86]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[87]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[88]\ttrain-merror:0.14\ttest-merror:0.14\n",
      "[89]\ttrain-merror:0.133333\ttest-merror:0.133333\n",
      "[90]\ttrain-merror:0.133333\ttest-merror:0.133333\n",
      "[91]\ttrain-merror:0.14\ttest-merror:0.14\n",
      "[92]\ttrain-merror:0.133333\ttest-merror:0.133333\n",
      "[93]\ttrain-merror:0.126667\ttest-merror:0.126667\n",
      "[94]\ttrain-merror:0.126667\ttest-merror:0.126667\n",
      "[95]\ttrain-merror:0.126667\ttest-merror:0.126667\n",
      "[96]\ttrain-merror:0.126667\ttest-merror:0.126667\n",
      "[97]\ttrain-merror:0.126667\ttest-merror:0.126667\n",
      "[98]\ttrain-merror:0.12\ttest-merror:0.12\n",
      "[99]\ttrain-merror:0.12\ttest-merror:0.12\n",
      "predicting, classification error=0.120000\n",
      "[0]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[1]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[2]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[3]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[4]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[5]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[6]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[7]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[8]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[9]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[10]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[11]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[12]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[13]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[14]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[15]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[16]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[17]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[18]\ttrain-merror:0.18\ttest-merror:0.18\n",
      "[19]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[20]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[21]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[22]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[23]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[24]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[25]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[26]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[27]\ttrain-merror:0.173333\ttest-merror:0.173333\n",
      "[28]\ttrain-merror:0.166667\ttest-merror:0.166667\n",
      "[29]\ttrain-merror:0.166667\ttest-merror:0.166667\n",
      "[30]\ttrain-merror:0.166667\ttest-merror:0.166667\n",
      "[31]\ttrain-merror:0.166667\ttest-merror:0.166667\n",
      "[32]\ttrain-merror:0.166667\ttest-merror:0.166667\n",
      "[33]\ttrain-merror:0.166667\ttest-merror:0.166667\n",
      "[34]\ttrain-merror:0.166667\ttest-merror:0.166667\n",
      "[35]\ttrain-merror:0.16\ttest-merror:0.16\n",
      "[36]\ttrain-merror:0.153333\ttest-merror:0.153333\n",
      "[37]\ttrain-merror:0.153333\ttest-merror:0.153333\n",
      "[38]\ttrain-merror:0.153333\ttest-merror:0.153333\n",
      "[39]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[40]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[41]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[42]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[43]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[44]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[45]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[46]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[47]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[48]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[49]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[50]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[51]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[52]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[53]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[54]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[55]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[56]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[57]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[58]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[59]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[60]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[61]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[62]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[63]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[64]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[65]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[66]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[67]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[68]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[69]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[70]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[71]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[72]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[73]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[74]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[75]\ttrain-merror:0.146667\ttest-merror:0.146667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[77]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[78]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[79]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[80]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[81]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[82]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[83]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[84]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[85]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[86]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[87]\ttrain-merror:0.146667\ttest-merror:0.146667\n",
      "[88]\ttrain-merror:0.14\ttest-merror:0.14\n",
      "[89]\ttrain-merror:0.133333\ttest-merror:0.133333\n",
      "[90]\ttrain-merror:0.133333\ttest-merror:0.133333\n",
      "[91]\ttrain-merror:0.14\ttest-merror:0.14\n",
      "[92]\ttrain-merror:0.133333\ttest-merror:0.133333\n",
      "[93]\ttrain-merror:0.126667\ttest-merror:0.126667\n",
      "[94]\ttrain-merror:0.126667\ttest-merror:0.126667\n",
      "[95]\ttrain-merror:0.126667\ttest-merror:0.126667\n",
      "[96]\ttrain-merror:0.126667\ttest-merror:0.126667\n",
      "[97]\ttrain-merror:0.126667\ttest-merror:0.126667\n",
      "[98]\ttrain-merror:0.12\ttest-merror:0.12\n",
      "[99]\ttrain-merror:0.12\ttest-merror:0.12\n",
      "predicting, classification error=0.120000\n"
     ]
    }
   ],
   "source": [
    "watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
    "num_round = 100\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist );\n",
    "# get prediction\n",
    "pred = bst.predict( xg_test );\n",
    "\n",
    "print ('predicting, classification error=%f' % (sum( int(pred[i]) != test_Y[i] for i in range(len(test_Y))) / float(len(test_Y)) ))\n",
    "\n",
    "# do the same thing again, but output probabilities\n",
    "param['objective'] = 'multi:softprob'\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist );\n",
    "# Note: this convention has been changed since xgboost-unity\n",
    "# get prediction, this is in 1D array, need reshape to (ndata, nclass)\n",
    "yprob = bst.predict(xg_test ).reshape( test_Y.shape[0], 3 )\n",
    "ylabel = np.argmax(yprob, axis=1)\n",
    "\n",
    "print ('predicting, classification error=%f' % (sum( int(ylabel[i]) != test_Y[i] for i in range(len(test_Y))) / float(len(test_Y)) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: b'p,x,s,n,t,p,f,c,n,k,e,e,s,s,w,w,p,w,o,p,k,s,u'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-87354194bbbe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## compare two data input method.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mload_svmlight_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/heart_scale/agaricus-lepiota.data.txt'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# loading datasets in the svmlight/libsvm format.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mxgm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mxgm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\datasets\\svmlight_format.py\u001b[0m in \u001b[0;36mload_svmlight_file\u001b[1;34m(f, n_features, dtype, multilabel, zero_based, query_id, offset, length)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \"\"\"\n\u001b[0;32m    146\u001b[0m     return tuple(load_svmlight_files([f], n_features, dtype, multilabel,\n\u001b[1;32m--> 147\u001b[1;33m                                      zero_based, query_id, offset, length))\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\datasets\\svmlight_format.py\u001b[0m in \u001b[0;36mload_svmlight_files\u001b[1;34m(files, n_features, dtype, multilabel, zero_based, query_id, offset, length)\u001b[0m\n\u001b[0;32m    288\u001b[0m     r = [_open_and_load(f, dtype, multilabel, bool(zero_based), bool(query_id),\n\u001b[0;32m    289\u001b[0m                         offset=offset, length=length)\n\u001b[1;32m--> 290\u001b[1;33m          for f in files]\n\u001b[0m\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m     if (zero_based is False or\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\datasets\\svmlight_format.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    288\u001b[0m     r = [_open_and_load(f, dtype, multilabel, bool(zero_based), bool(query_id),\n\u001b[0;32m    289\u001b[0m                         offset=offset, length=length)\n\u001b[1;32m--> 290\u001b[1;33m          for f in files]\n\u001b[0m\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m     if (zero_based is False or\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\datasets\\svmlight_format.py\u001b[0m in \u001b[0;36m_open_and_load\u001b[1;34m(f, dtype, multilabel, zero_based, query_id, offset, length)\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mactual_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindptr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                 _load_svmlight_file(f, dtype, multilabel, zero_based, query_id,\n\u001b[1;32m--> 178\u001b[1;33m                                     offset, length)\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;31m# convert from array.array, give data the right dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\datasets\\_svmlight_format.pyx\u001b[0m in \u001b[0;36msklearn.datasets._svmlight_format._load_svmlight_file\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: b'p,x,s,n,t,p,f,c,n,k,e,e,s,s,w,w,p,w,o,p,k,s,u'"
     ]
    }
   ],
   "source": [
    "## compare two data input method.\n",
    "import os\n",
    "X_train, y_train=load_svmlight_file(os.getcwd() + '/heart_scale/agaricus-lepiota.data.txt') # loading datasets in the svmlight/libsvm format.\n",
    "xgm = xgb.XGBClassifier(max_depth=3)\n",
    "xgm.fit(X_train, y_train)\n",
    "y_pred = xgm.predict(X_train)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_train, predictions)\n",
    "print(xgm)\n",
    "print(\"XGBoost Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
