{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TV Script Generation\n",
    "In this project, you'll generate your own [Simpsons](https://en.wikipedia.org/wiki/The_Simpsons) TV scripts using RNNs.  You'll be using part of the [Simpsons dataset](https://www.kaggle.com/wcukierski/the-simpsons-by-the-data) of scripts from 27 seasons.  The Neural Network you'll build will generate a new TV script for a scene at [Moe's Tavern](https://simpsonswiki.com/wiki/Moe's_Tavern).\n",
    "## Get the Data\n",
    "The data is already provided for you.  You'll be using a subset of the original dataset.  It consists of only the scenes in Moe's Tavern.  This doesn't include other versions of the tavern, like \"Moe's Cavern\", \"Flaming Moe's\", \"Uncle Moe's Family Feed-Bag\", etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import helper\n",
    "import os\n",
    "\n",
    "data_dir = os.getcwd() + '/../data/simpsons/moes_tavern_lines.txt'\n",
    "text = helper.load_data(data_dir)\n",
    "# Ignore notice, since we don't use it for analysing the data\n",
    "text = text[81:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "Play around with `view_sentence_range` to view different parts of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "Roughly the number of unique words: 11492\n",
      "Number of scenes: 262\n",
      "Average number of sentences in each scene: 15.248091603053435\n",
      "Number of lines: 4257\n",
      "Average number of words in each line: 11.50434578341555\n",
      "\n",
      "The sentences 0 to 10:\n",
      "Moe_Szyslak: (INTO PHONE) Moe's Tavern. Where the elite meet to drink.\n",
      "Bart_Simpson: Eh, yeah, hello, is Mike there? Last name, Rotch.\n",
      "Moe_Szyslak: (INTO PHONE) Hold on, I'll check. (TO BARFLIES) Mike Rotch. Mike Rotch. Hey, has anybody seen Mike Rotch, lately?\n",
      "Moe_Szyslak: (INTO PHONE) Listen you little puke. One of these days I'm gonna catch you, and I'm gonna carve my name on your back with an ice pick.\n",
      "Moe_Szyslak: What's the matter Homer? You're not your normal effervescent self.\n",
      "Homer_Simpson: I got my problems, Moe. Give me another one.\n",
      "Moe_Szyslak: Homer, hey, you should not drink to forget your problems.\n",
      "Barney_Gumble: Yeah, you should only drink to enhance your social skills.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "view_sentence_range = (0, 10)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "print('Dataset Stats')\n",
    "print('Roughly the number of unique words: {}'.format(len({word: None for word in text.split()})))\n",
    "scenes = text.split('\\n\\n')\n",
    "print('Number of scenes: {}'.format(len(scenes)))\n",
    "sentence_count_scene = [scene.count('\\n') for scene in scenes]\n",
    "print('Average number of sentences in each scene: {}'.format(np.average(sentence_count_scene)))\n",
    "#[char for title in doc for word in title for char in word]\n",
    "sentences = [sentence for scene in scenes for sentence in scene.split('\\n')]\n",
    "print('Number of lines: {}'.format(len(sentences)))\n",
    "word_count_sentence = [len(sentence.split()) for sentence in sentences]\n",
    "print('Average number of words in each line: {}'.format(np.average(word_count_sentence)))\n",
    "\n",
    "print()\n",
    "print('The sentences {} to {}:'.format(*view_sentence_range))\n",
    "print('\\n'.join(text.split('\\n')[view_sentence_range[0]:view_sentence_range[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocessing Functions\n",
    "The first thing to do to any dataset is preprocessing.  Implement the following preprocessing functions below:\n",
    "- Lookup Table\n",
    "- Tokenize Punctuation\n",
    "\n",
    "### Lookup Table\n",
    "To create a word embedding, you first need to transform the words to ids.  In this function, create two dictionaries:\n",
    "- Dictionary to go from the words to an id, we'll call `vocab_to_int`\n",
    "- Dictionary to go from the id to word, we'll call `int_to_vocab`\n",
    "\n",
    "Return these dictionaries in the following tuple `(vocab_to_int, int_to_vocab)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_set: {'problems', 'i', 'meet', 'on', 'hey', 'not', 'mike', 'your', 'is', 'homer', 'back', 'an', 'only', 'carve', 'anybody', 'matter', 'these', 'puke', 'enhance', 'whats', 'moe_szyslak', 'of', 'barney_gumble', 'rotch', 'effervescent', 'elite', 'tavern', \"you're\", 'got', 'there', 'eh', 'has', 'drink', 'check', 'seen', 'lately', 'gonna', 'give', 'hello', 'where', 'pick', 'last', 'my', 'homer_simpson', 'self', \"moe's\", 'another', 'name', 'normal', 'days', \"i'm\", 'you', 'ice', 'and', 'social', 'hold', 'forget', 'one', 'me', 'the', 'should', 'bart_simpson', \"i'll\", 'listen', 'catch', 'moe', 'skills', 'with', 'to', 'little', 'yeah'}\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import problem_unittests as tests\n",
    "\n",
    "def create_lookup_tables(text):\n",
    "    \"\"\"\n",
    "    Create lookup tables for vocabulary\n",
    "    :param text: The text of tv scripts split into words\n",
    "    :return: A tuple of dicts (vocab_to_int, int_to_vocab)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    vocab_set = set(text)\n",
    "    print('vocab_set:',vocab_set)\n",
    "    vocab_to_int = {word:id_t for id_t,word in enumerate(vocab_set)}\n",
    "    int_to_vocab = {id_t:word for id_t,word in enumerate(vocab_set)}\n",
    "    return vocab_to_int, int_to_vocab\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_create_lookup_tables(create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Punctuation\n",
    "We'll be splitting the script into a word array using spaces as delimiters(分隔符).  However, punctuations like periods(句点) and exclamation(感叹号) marks make it hard for the neural network to distinguish between the word \"bye\" and \"bye!\".\n",
    "\n",
    "Implement the function `token_lookup` to return a dict that will be used to tokenize symbols like \"!\" into \"||Exclamation_Mark||\".  Create a dictionary for the following symbols where the symbol is the key and value is the token:\n",
    "- Period ( . )\n",
    "- Comma ( , )\n",
    "- Quotation Mark ( \" )\n",
    "- Semicolon ( ; )\n",
    "- Exclamation mark ( ! )\n",
    "- Question mark ( ? )\n",
    "- Left Parentheses ( ( )\n",
    "- Right Parentheses ( ) )\n",
    "- Dash ( -- )\n",
    "- Return ( \\n )\n",
    "\n",
    "This dictionary will be used to token the symbols and add the delimiter (space) around it.  This separates the symbols as it's own word, making it easier for the neural network to predict on the next word. Make sure you don't use a token that could be confused as a word. Instead of using the token \"dash\", try using something like \"||dash||\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def token_lookup():\n",
    "    \"\"\"\n",
    "    Generate a dict to turn punctuation into a token.\n",
    "    :return: Tokenize dictionary where the key is the punctuation and the value is the token\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    symbol_dict = {'.':'||Period||',',':'||Comma||','\"':'||QuotationMark||',\n",
    "                  ';':'||Semicolon||','!':'||ExclamationMark||','?':'||QuestionMark||',\n",
    "                  '(':'||LeftParentheses||',')':'||RightParentheses||','--':'||Dash||',\n",
    "                  '\\n':'||Return||'}\n",
    "    return symbol_dict\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_tokenize(token_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the data and save it to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_set: {'exchange', 'mostrar', 'dean', 'swan', 'touched', 'dispenser', 'sexual', 'resist', 'coach:', 'jailbird', 'ralph', 'graveyard', 'lotsa', 'nerd', 'stranger:', 'jobless', 'innocent', 'mess', 'panties', 't-shirt', 'manatee', 'drunks', 'bowl', 'hurry', 'chief', 'glove', 'f', 'unfamiliar', 'freaking', 'peter', 'hosting', 'friction', 'flailing', 'tidy', 'brings', 'uncomfortable', 'breaking', \"cat's\", 'themselves', 'underpants', \"aristotle's\", 'depression', 'alcoholic', 'fritz', 'slight', 'live', 'compliment', 'eminence', 'twenty-five', 'dang', 'protestantism', 'enemies', 'sincere', 'dallas', 'howya', 'missed', 'showed', 'shutup', 'rationalizing', 'website', \"that's\", 'magic', 'in-in-in', 'forty-seven', 'kucinich', 'mother', 'gotten', 'kisser', 'kept', \"daughter's\", 'floated', 'sleigh-horses', 'toe', 'twelve-step', 'troy', 'fork', 'courthouse', 'cents', 'pleasure', 'forbidden', 'smelly', 'presidents', 'cake', '4x4', 'acquaintance', 'i', 'whoa', 'e', 'letters', 'is', 'then:', 'aerosmith', 'half-beer', 'fund', 'appropriate', 'involved', 'eh', 'captain:', 'big', 'hitler', 'air', 'old-time', 'arguing', 'fifty', '3rd_voice:', 'snotball', 'first', 'handler', 'release', 'animals', 'pine', 'slot', 'vehicle', 'connection', 'aiden', 'already', 'lincoln', 'harvesting', 'twentieth', 'afterglow', 'wittgenstein', 'end', 'whispers', 'f-l-a-n-r-d-s', 'sledge-hammer', 'strategizing', 'pick', 'land', 'hotline', 'blood-thirsty', 'crayola', 'partner', 'stomach', 'kick-ass', 'jeers', 'batmobile', 'clench', 'power', 'weight', 'banquo', 'uhhhh', 'thorn', 'mmmmm', \"elmo's\", 'plow', 'dna', 'hub', 'something:', 'beneath', 'comeback', 'believe', 'meaningless', 'standards', 'occupancy', 'denver', 'sickens', 'invisible', 'television', 'parking', 'loafers', 'lobster', 'mm', 'killjoy', 'whaaa', 'sub-monkeys', 'singing', 'recent', 'chew', 'occasion', 'duh', 'easy', \"'cause\", 'gees', 'hunting', 'rumor', 'mice', 'warily', 'wealthy', 'horrible', 'sinister', 'what', 'dislike', 'courage', 'slipped', 'rookie', 'four-drink', 'cheapskates', 'barbed', 'willy', 'listen', 'disposal', 'campaign', 'male_inspector:', 'homers', 'souvenir', 'warm_female_voice:', 'slice', 'dollface', 'moustache', 'carve', \"let's\", 'absolutely', 'fluoroscope', 'fixes', 'feed', 'sooo', 'listening', '||semicolon||', 'peanuts', 'director:', 'calls', 'remodel', 'understood', 'pig', 'stu', 'love-matic', 'graves', 'cuff', 'nervously', 'smoke', 'result', 'flack', 'tourist', 'word', 'poin-dexterous', 'tv', 'tab', 'partly', 'tuna', 'releases', 'hitchhike', 'gluten', 'young_barfly:', 'invulnerable', 'letter', 'derisive', 'tony', 'hearts', 'eyeball', 'head-gunk', 'stage', 'rump', 'mom', 'radishes', 'ball-sized', '_babcock:', '||questionmark||', 'chapel', 'blood', 'mistakes', 'duff', 'human', 'entering', 'multi-national', 'bow', 'hoax', 'true', 'patron_#2:', 'shrugging', 'tonic', \"yieldin'\", 'squeals', 'workers', 'nucular', 'kent_brockman:', 'lover', 'acting', \"could've\", \"tab's\", 'tuborg', 'stumble', 'wayne:', 'gone', 'trustworthy', \"'ceptin'\", 'americans', 'gus', 'aah', 'buttocks', 'nurse', 'where', \"other's\", 'unrelated', 'slobs', 'app', 'kicks', 'mop', 'yee-haw', 'life-threatening', 'nuclear', 'moment', 'punishment', 'aerospace', 'cowardly', 'pumping', 'bidet', 'humiliation', 'express', 'meaningful', 'ruined', 'life-partner', 'arrange', 'trash', 'ideal', 'them', \"can'tcha\", 'yellow', 'pusillanimous', 'buds', \"grandmother's\", 'sometimes', 'bathtub', 'fl', 'pointing', 'afford', 'issuing', 'goes', 'progress', 'classy', 'sued', 'squad', 'whatever', 'badly', 'grade', 'p-k', 'stooges', 'caper', 'honey', 'six', 'maiden', 'market', 'drunkening', 'w-a-3-q-i-zed', 'fleabag', 'chuckling', 'lenford', 'question', 'heroism', 'genius', 'clammy', 'presided', 'escort', 'prove', 'sympathizer', 'elizabeth', 'indifferent', 'triumphantly', 'man_at_bar:', 'school', 'whoopi', 'lovely', 'specials', 'spews', 'poem', 'frozen', 'sistine', 'artie_ziff:', 'tentative', 'hateful', 'troy_mcclure:', 'laid', 'boozebag', 'hollye', 'happier', 'singer', 'celebration', 'courts', \"'roids\", 'start', 'wiggle', 'moe-clone:', 'favorite', 'hidden', 'him', 'discriminate', 'salvador', 'medicine', 'save', 'enjoys', 'tubman', 'collapse', 'buying', 'committee', 'intoxicated', 'brace', 'ran', 'fools', 'toy', 'accent', 'rainier', 'prime', '_marvin_monroe:', 'drag', 'lindsay_naegle:', 'filled', 'lend', 'legally', 'fat', 'shocked', 'spiritual', 'expensive', 'someday', 'appalled', 'narrator:', 'hugh:', 'keeps', 'bart', \"renee's\", 'cheated', 'xx', 'high', 'incriminating', \"men's\", 'do', 'sight-unseen', 'cattle', 'grow', 'irishman', 'blessing', 'pair', 'gives', 'prolonged', 'tang', 'address', 'soothing', 'faces', 'waitress', 'krusty_the_clown:', 'pretentious_rat_lover:', \"d'ya\", 'lenses', 'sticking', 'obese', 'rotten', 'prayers', 'meal', 'hobo', 'shop', 'somehow', 'sense', 'shot', 'experiments', 'huggenkiss', 'religion', 'tick', 'numbers', 'vodka', 'theatah', 'english', 'hold', 'offer', 'holidays', 'beyond', 'gets', 'dance', 'lights', 'hippies', 'jukebox_record:', 'rolling', 'reserve', 'switched', \"son's\", 'youuu', 'gator', \"wait'll\", 'guess', '_powers:', 'kick', 'daaaaad', 'clown-like', 'snap', 'skins', 'choked', 'arts', 'rainforest', 'honored', 'copy', 'heard', 'nelson_muntz:', 'alley', \"collector's\", 'acronyms', 'hearing', 'snail', 'but', \"'n'\", 'rather', 'prize', 'seats', 'sector', 'window', 'nudge', 'd', \"cheerin'\", 'urinal', 'actors', 'reynolds', 'fountain', 'halvsies', 'especially', 'burt_reynolds:', 'sixty-five', 'glamour', 'patty', 'conditioning', 'involving', 'macho', 'creme', 'sobbing', 'they', 'nigeria', 'abolish', 'mines', 'iddilies', 'tokens', 'rickles', 'japanese', 'heatherton', 'our', 'child', 'wedding', 'journey', 'sponsor', 'rumaki', 'badmouths', 'slays', 'jets', 'chance', 'argue', 'mount', 'lanes', 'race', 'celeste', 'asking', 'intention', 'say', 'plastic', 'crooks', 'labels', 'corporate', 'ashtray', 'richard', 'collette:', 'products', 'reasons', 'tears', 'piling', 'stolen', 'j', 'loss', 'one', 'tire', 'sees/', 'tom', 'inherent', 'pile', 'proper', 'interested', 'strangles', 'jockey', 'gestated', 'goal', 'old_jewish_man:', \"bartender's\", 'mock-up', 'try', 'lately', 'dealt', 'murmurs', 'neon', 'martini', 'cesss', 'padre', \"haven't\", 'parrot', 'fridge', 'work', \"eatin'\", 'either', 'sheriff', 'if', 'crowd:', 'windelle', 'abusive', 'instead', 'tempting', 'saw', 'eternity', 'rats', 'appearance-altering', 'disguise', 'drederick', 'exhibit', 'presents', 'majority', 'conclusions', 'department', 'assent', \"football's\", \"wouldn't-a\", 'hands', 'stupidest', 'fuzzlepitch', 'stretches', 'party', 'skydiving', 'remain', 'virtual', \"industry's\", 'sausage', 'len-ny', 'ripcord', 'pepper', 'beers', 'dirty', 'libido', 'op', 'woman', 'accept', 'treehouse', 'little_hibbert_girl:', 'chauffeur:', 'pained', 'baritone', 'dignity', 'hygienically', 'unsafe', 'during', 'country', 'sweat', 'laugh', 'gr-aargh', 'blues', 'remembers', 'priest', 'inquiries', 'nonchalantly', 'meaning', 'laney', 'heh', 'arabs', 'pre-game', 'swelling', 'played', 'aisle', 'frink-y', 'harmony', \"playin'\", 'veteran', 'freeze', 'leprechaun', 'doppler', 'versus', 'sunglasses', 'conference', \"lenny's\", 'delicately', 'grieving', 'cliff', 'information', 'flames', 'funeral', 'backgammon', 'changing', 'whaddaya', 'glass', 'hammer', 'bucket', 'suru', 'musta', 'bounced', 'perhaps', 'snaps', 'warmth', 'steinbrenner', \"ladies'\", 'smurfs', 'jeez', 'jay_leno:', 'mediterranean', 'extremely', 'stuck', 'checks', 'ribbon', 'butterball', 'trade', 'eu', 'microbrew', 'cell', 'contact', 'understood:', 'kicked', 'subject', 'ohhhh', 'cost', 'eve', 'complete', 'shark', 'drawing', 'shores', 'hank_williams_jr', 'alpha-crow', 'unjustly', 'exhale', 'chair', 'canoodling', \"rasputin's\", 'smoker', 'joe', 'neighbor', 'smart', \"y'money's\", 'oh-so-sophisticated', 'myself', 'roomy', 'l', 'cocktail', 'legal', 'death', 'b-day', 'direction', 'color', 'parked', 'automobiles', 'toledo', 'mozzarella', \"tree's\", \"g'ahead\", 'notch', '||dash||', 'finished', 'syrup', 'bill', 'finale', 'stay-puft', \"i'm\", \"c'mere\", 'belong', 'weather', 'ahhh', \"stinkin'\", 'test', 'yourselves', 'shame', \"gentleman's\", 'dazed', 'africa', 'smelling', 'ourselves', 'teeth', 'andrew', 'tha', 'kirk_voice_milhouse:', 'call', 'yuh-huh', 'princess', \"beggin'\", 'fifteen', 'sudoku', 'bottle', 'minimum', 'opens', 'aww', 'position', 'lurleen_lumpkin:', 'bid', 'chilly', 'junior', 'fayed', 'donor', 'focus', 'slit', 'devils:', 'lied', 'hide', 'learned', 'anti-lock', 'super-nice', 'damage', 'hard', 'agents', 'lowering', 'malibu', 'warren', 'gabriel:', \"fightin'\", 'stand', 'crack', 'umm', 'unusual', \"you've\", 'finest', 'bono', 'queen', 'melodramatic', 'shout', 'comic_book_guy:', 'er', 'silent', 'sexy', 'awe', 'decided', \"fendin'\", 'wait', 'stands', 'nbc', 'dollars', 'leno', 'shape', 'occasional', 'unattended', 'whoo', 'feeling', 'kickoff', 'beaumont', 'uneasy', \"show's\", 'filthy', 'attempting', 'arrest', 'walther', 'third', 'safecracker', 'mouse', \"s'okay\", 'wood', 'at', 'robot', 'yee-ha', 'million', 'rummy', 'frog', 'rector', 'swear', 'post-suicide', 'cakes', 'flatly', 'chunk', 'lizard', 'crowded', 'windex', 'dig', 'turkey', 'stairs', 'catch', 'fan', 'figures', 'plywood', 'ruin', 'used', 'albert', 'hootie', 'supreme', 'latin', \"tootin'\", 'trenchant', 'stock', 'impeach', 'poulet', 'cars', 'broken:', 'winks', \"they'd\", 'rabbits', 'unhappy', \"bladder's\", 'keep', 'celebrities', 'plain', 'gamble', 'oil', 'bourbon', 'usual', 'lost', 'hotel', 'emphasis', 'sleeps', 'sells', 'good-looking', 'beatings', 'chorus:', 'vengeful', 'once', 'five', 'lucky', 'arms', 'annual', 'tear', 'stole', 'french', 'gang', 'greystash', 'intoxicants', 'wangs', 'lie', 'teach', 'dress', \"goin'\", 'pantry', 'drinks', 'local', 'mix', 'vin', 'cheaped', 'teenage_barney:', 'wrapped', 'lump', 'guns', 'fausto', 'lookalike:', \"wino's\", 'writer:', 'two', 'protesters', 'imitating', \"there's\", 'boy', 'chin', 'tactful', 'attend', 'price', 'grudgingly', 'unable', 'nap', \"wife's\", 'theatrical', 'writing', \"homer'll\", 'she', 'mean', 'anyone', 'repeated', 'kidney', 'los', \"bart's\", 'burps', 'smell', 'friend:', 'alcohol', 'mob', 'i/you', 'enjoy', 'asses', 'sister', 'christmas', 'sheets', 'considering:', 'sickened', 'venom', 'mommy', 'superior', 'tv_wife:', \"'topes\", 'thing', 'hilton', 'debonair', 'harvard', 'bears', 'results', 'brine', 'sideshow', 'betrayed', 'traffic', 'dreamed', 'no', 'safety', 'moan', 'presto:', 'tiger', \"hole'\", 'squadron', 'hollowed-out', 'possibly', 'original', 'most:', 'riding', 'african', 'knuckles', 'tornado', 'random', 'inexorable', 'lot', 'gifts', 'selection', 'sneering', 'almost', 'cheerier', 'festival', 'king', 'file', 'cockroach', 'bushes', 'square', '50%', 'duffman:', 'thrust', 'tipsy', 'righ', 'depressant', 'ladder', \"we'll\", 'guard', 'amazed', 'professor_jonathan_frink:', 'formico:', 'wounds', 'new_health_inspector:', 'commission', 'unusually', 'flat', 'water', 'chapter', 'pleased', 'coin', 'pissed', 'militia', 'parenting', 'mt', 'appreciate', 'straight', 'lumpa', 'century', 'gear-head', 'brunch', 'handshake', 'wiggum', 'recommend', 'digging', \"seein'\", 'fury', 'politicians', 'rancid', 'pond', 'small_boy:', 'toilet', 'eddie', 'man', 'weird', 'way:', 'nards', 'hug', 'tape', 'drove', 'terrifying', 'garbage', 'sobo', 'oooo', 'available', 'torn', 'period', 'drinker', 'jane', 'telephone', 'ab', 'panicked', 'priority', \"ragin'\", 'fortune', 'ale', 'demo', 'jernt', 'reporter:', 'runs', 'beeps', 'gil_gunderson:', 'tell', 'offended', 'klingon', 'lisa', 'losing', 'scum-sucking', 'kidding', \"burnin'\", 'cruise', 'swill', 'designated', 'join', 'showing', 'counterfeit', 'exit', 'blinds', 'accelerating', 'stop', 'grampa', 'gum', 'coincidentally', 'further', 'shoo', 'or', 'candy', 'ugliness', 'togetherness', 'jackass', 'customers', 'principal', 'written', 'dime', 'appointment', \"i've\", 'appealing', \"battin'\", 'rounds', 'tells', 'avec', 'correct', 'beady', 'willing', 'goodbye', 'van', 'potatoes', 'conversion', 'flanders', 'chow', 'muscle', 'blooded', 'egg', 'judge_snyder:', 'scrutinizing', 'whatchamacallit', 'entrance', 'forgot', 'starters', \"that'd\", 'rings', 'prohibit', 'quality', 'marge_simpson:', 'cola', 'thanksgiving', 'raccoons', \"sayin'\", 'miss', 'temp', 'rap', 'milhouses', 'whaddya', 'cleaner', 'knew', 'times', 'down', 'seems', 'computer', 'extended', 'mountain', 'waltz', 'newest', 'temporarily', 'koholic', 'nick', 'perverted', 'driving', 'marguerite:', 'scornfully', 'terrace', 'dexterous', 'extra', 'half', 'well', 'priceless', \"foolin'\", \"you're\", 'forty-five', 'socratic', 'correction', 'andalay', 'spouses', 'ad', 'through', 'date', 'dame', 'rafter', \"he'd\", 'whether', 'splattered', 'ten', 'patron_#1:', 'simultaneous', 'frightened', 'cushion', 'joy', 'derek', 'delicate', 'smiled', 'leg', \"they've\", 'actress', 'boozehound', 'languages', 'sits', 'patient', 'meant', 'miss_lois_pennycandy:', 'utility', 'intrigued', 'rasputin', 'maxed', 'fraud', 'heavens', \"didn't\", \"o'\", 'choice:', 'giant', 'spelling', 'hideous', 'non-losers', 'encouraging', 'stool', 'jack', 'renee:', 'cheery', 'noises', 'feminine', 'book_club_member:', \"dolph's_dad:\", 'outside', 'coney', 'wife-swapping', 'pint', 'elite', 'swell', 'smugglers', 'cases', 'replace', 'cool', \"singin'\", 'theater', 'schedule', 'benjamin:', 'respect', 'farthest', 'system', 'mumbling', 'overturned', 'undated', 'fair', 'normals', 'rub-a-dub', 'season', 'maher', 'put', 'knowledge', 'teenage', 'tale', \"askin'\", 'cute', 'pfft', 'politics', 'kermit', \"wonderin'\", 'bedroom', 'dr', 'legend', 'together', 'history', 'and/or', 'doll-baby', 'formico', 'incognito', 'smoothly', 'klown', 'supermodel', 'geyser', 'mahatma', 'life-extension', 'marvelous', 'part', 'handoff', 'stir', 'hibachi', 'prizefighters', 'kind', 'adjust', 'enjoyed', 'cares', 'whoever', 'principles', 'butt', 'joey', 'begins', 'upn', \"somethin':\", 'groans', 'characteristic', 'blurbs', 'advantage', 'then', \"how'd\", 'winces', 'therapy', 'seething', 'composite', 'buddies', 'dancing', 'hops', 'share', 'vicious', 'percent', 'souped', 'wiener', 'sixty-nine', 'accusing', 'philosophic', 'space-time', 'steamed', 'became', 'food', 'bucks', 'amnesia', 'boys', 'self', 'failed', 'served', \"robbin'\", 'arm-pittish', 'marjorie', 'decision', 'elocution', 'hiya', 'many', 'dynamite', 'connor', 'fine', 'jubilant', 'count', 'moe-ron', 'sour', 'cheap', 'sob', 'omit', 'fire_inspector:', \"messin'\", 'beverage', 'easy-going', 'bus', 'backbone', 'jaegermeister', 'avenue', 'ehhh', 'gruff', 'uh-huh', 'dead', 'edison', 'schemes', 'noosey', 'lobster-politans', 'scatter', 'mis-statement', 'landlord', 'nuked', 'haw', 'caught', 'the', 'notably', \"betsy'll\", 'failure', \"table's\", 'blob', 'design', 'stirring', 'may', 'matter', 'transmission', 'skin', \"sittin'\", 'spirit', 'greedy', \"kid's\", 'poorer', 'amused', 'beloved', 'tanked-up', \"clancy's\", 'finish', 'filth', 'burglary', 'bold', 'polish', 'brakes', 'bet', 'mathis', 'delicious', 'fellow', 'coast', 'ruint', 'szyslak', 'told', 'must', 'dennis', 'pre-recorded', 'tapping', 'bear', 'nahasapeemapetilon', 'champs', 'such', 'pussycat', 'honeys', 'tanking', 'entire', 'insulin', 'bowie', 'sex', 'hexa-', 'heave-ho', 'satisfied', 'gasp', '1979', 'lots', 'simpson', 'age', 'soaps', 'upon', 'conditioner', 'wish-meat', \"fun's\", 'larry:', 'congoleum', \"mopin'\", 'skunk', 'tonight', 'horns', 'music', 'disgusted', 'sticking-place', 'treat', 'nine', 'schorr', 'cozy', \"'s\", 'right', 'score', 'whistling', 'stripe', 'softer', \"cleanin'\", 'pub', 'lecture', 'desperately', 'hours', 'baloney', 'dennis_kucinich:', 'swimming', \"hawkin'\", 'uniforms', 'gag', 'test-', 'furniture', 'military', 'chumbawamba', 'pack', 'germs', \"professor's\", 'always', 'closet', 'southern', 'with', 'yells', 'ninety-seven', 'agnes_skinner:', 'pregnancy', 'store-bought', 'west', 'rubs', 'philip', 'badges', 'rest', 'platinum', 'churchy', \"doin'\", 'column', 'indignant', 'teacup', 'legs', 'mid-seventies', 'sang', 'on', 'd眉ffenbraus', 'blobbo', 'man:', 'dejected', 'las', 'joey_kramer:', 'shag', 'bachelorhood', 'sadistic_barfly:', 'form', 'yes', 'pleading', 'brave', 'addiction', 'problemo', 'crossed', \"buyin'\", 'evening', 'sentimonies', 'gunk', 'string', 'jeff', 'cow', 'dressed', '8', 'before', 'lifetime', 'bail', 'thousands', 'pro', 'happen', \"bo's\", 'strolled', 'mcbain', 'march', 'society', 'powerful', 'bathroom', 'laramie', \"pullin'\", 'flustered', 'enveloped', \"she'd\", 'sunday', 'fudd', 'customer', \"homer's\", 'only', 'civilization', 'box', 'quarterback', 'despite', 'bashir', 'confused', 'tavern', 'hostages', 'brandy', 'trainers', 'severe', 'wonderful', 'hispanic_crowd:', 'womb', 'blew', 'alphabet', 'lisa_simpson:', 'feel', 'index', 'country-fried', 'rewound', 'microwave', 'achem', 'strips', 'brotherhood', 'sniffs', \"s'cuse\", 'matter-of-fact', 'jolly', 'suffering', '7-year-old_brockman:', 'booze-bags', 'reciting', 'rain', 'closer', 'stadium', 'chubby', 'barney-guarding', 'movie', 'sadly', 'catch-phrase', 'presidential', \"can't\", 'seymour_skinner:', 'awkward', 'waylon_smithers:', 'juan', \"crawlin'\", 'horrified', 'milks', 'retired', 'mind-numbing', 'meatpies', 'pepto-bismol', 'chuckles', 'clean', 'wiping', 'carl', 'rev', 'pledge', 'prep', 'leathery', 'wizard', 'jay', 'birthday', 'spit-backs', 'huge', 'temple', 'nevada', 'breathtaking', 'born', 'jubilation', 'size', 'sat-is-fac-tion', 'cigarette', 'their', 'answer', 'boxcar', 'different', 'broadway', 'bubble', 'refreshing', 'hate-hugs', 'eaten', 'ripping', 'glitterati', 'quimby_#2:', 'playing', 'accidents', 'jukebox', 'sweeter', 'looser', 'fledgling', 'slaps', 'madison', 'oak', 'coaster', 'cold', 'locked', 'ungrateful', 'effervescence', 'frescas', 'recruiter', 'moonshine', 'tv-station_announcer:', 'newsletter', 'astronaut', 'retain', 'old', 'match', 'shoes', 'buttons', 'kidneys', 'grace', 'society_matron:', 'benjamin', 'train', 'hmf', 'dreamy', 'generous', 'tap', 'assumed', 'roz:', 'screws', 'pipe', 'reminds', 'gently', 'front', 'should', 'tobacky', 'beauty', 'donate', 'supermarket', 'virility', \"edna's\", 'm', 'forced', 'janette', 'delays', 'theory', 'banned', 'suck', 'sec', 'crab', 'wake', \"dog's\", 'expense', 'volunteer', 'musses', 'moe-near-now', \"round's\", 'champignons', 'culkin', 'lurleen', 'though', 'swig', '脌', 'minus', 'slobbo', 'youngsters', 'side:', 'eight-year-old', 'business', 'anger', 'weeks', 'someplace', 'madman', 'laws', 'nice', 'hits', 'awake', 'slapped', 'troy:', 'flea:', 'fans', 'homie', 'and-and', 'abandon', 'victorious', 'ned', 'statesmanlike', 'simpsons', 'moxie', 'flash-fry', 'next', 'hooked', 'au', 'occurred', 'pinchpenny', 'likes', 'sweetest', 'upset', \"here's\", 'temples', 'slogan', 'loser', 'ninety-eight', 'bursts', 'advertise', 'patrons', \"fans'll\", 'wad', 'dank', 'employees', 'sam:', 'looks', 'jerks', 'takeaway', 'young_marge:', \"tatum'll\", 'realizing', 'lawyer', 'woozy', \"how's\", 'trust', 'die', 'daniel', 'calm', 'plenty', 'cockroaches', 'whale', 'getup', 'astonishment', 'whoa-ho', 'slightly', 'discuss', 'quickly', 'remains', 'moe-clone', \"marge's\", 'forgiven', 'associate', 'scratching', 'hers', 'ron', 'head', 'cock', 'dingy', \"murphy's\", 'glad', 'violin', 'smells', 'backward', 'swatch', 'ronstadt', 'turlet', 'sickly', 'latour', 'ivy-covered', \"drawin'\", \"changin'\", 'portfolium', 'woman:', 'pall', 'jesus', 'heals', 'corpses', 'effigy', 'wolveriskey', 'liven', 'maya:', 'bullet-proof', 'neanderthal', 'which', 'swamp', 'huh', 'cadillac', 'shooting', \"bart'd\", 'voice', '$42', 'grain', 'taylor', 'louse', 'walk', 'encore', 'church', 'government', 'mushy', 'young_homer:', 'hammy', 'donated', 'skills', 'fantasy', 'network', 'strong', 'muertos', 'kent', 'hardy', 'buffalo', 'scrape', 'vacations', 'meanwhile', 'toasting', 'helpless', 'ventriloquism', 'be-stain猫d', 'ceremony', 'fonda', 'straighten', \"soundin'\", 'poker', 'cage', 'crotch', 'villanova', 'e-z', \"c'mom\", 'spoken', 'loneliness', 'ziff', 'imported-sounding', 'football_announcer:', 'landfill', 'bar:', 'dishrag', \"toot's\", 'serve', 'bull', 'carll', 'yogurt', 'passenger', 'flips', 'mortgage', 'ratted', 'including', 'today', 'blubberino', 'destroyed', 'eighty-five', 'terrorizing', 'tight', 'seductive', 'decent', 'none', 'general', 'oughtta', 'twelve', 'calendars', 'montrer', 'crippling', 'hilarious', 'aboard', 'sings', 'show', 'paint', 'training', 'defensive', 'fevered', 'cops', 'might', 'charlie:', 'directions', 'increased', 'pep', 'designer', 'celebrity', 'wobbly', 'per贸n', 'easygoing', 'inserts', \"cashin'\", 'pizza', 'firm', 'manchego', 'tar-paper', 'judge', 'arm', 'troubles', 'w', 'furiously', 'illustrates', 'bills', 'raging', 'wantcha', 'pays', 'sticker', 'kim_basinger:', 'cronies', 'triangle', 'lipo', 'loudly', 'about', 'x-men', 'scam', 'stories', 'mention', 'tow-joes', \"i'd\", 'winston', 'frazier', 'ate', 'nominated', 'andy', 'musketeers', 'bothered', 'pull', 'dull', 'half-day', 'atlanta', 'patriotic', 'harm', 'ragtime', 'conversations', 'blur', 'ride', 'd眉ff', 'fad', 'honest', 'mission', 'kennedy', 'pulling', 'bartholom茅:', 'hero', 'solved', 'clubs', 'positive', '2nd_voice_on_transmitter:', 'reward', 'touches', 'literature', 'entirely', 'dejected_barfly:', 'breakfast', 'glen', 'even', 'feisty', 'misconstrue', \"springfield's\", 'freedom', 'betty:', 'tofu', 'sometime', 'cards', 'diaper', 'jokes', 'publishers', 'fruit', 'somewhere', 'tense', 'teams', 'clinton', 'necklace', 'forty-nine', 'delete', \"usin'\", 'remote', 'seek', 'vestigial', 'far', '100', 'horses', \"s'pose\", 'fool', 'greatly', 'wage', 'afraid', 'dictating', 'hand', 'judgments', 'kazoo', 'closing', 'new', 'loyal', 'time', 'starlets', 'mmmm', 'voice_on_transmitter:', 'sell', 'blend', 'crinkly', 'hollywood', 'awkwardly', 'grandkids', 'asks', 'confident', 'befouled', 'detective', 'figured', 'shhh', 'a-lug', 'fontaine', 'forward', \"it'd\", 'scientific', 'logos', 'david', 'eyeballs', 'si-lent', 'improv', 'thankful', 'suppose', 'distributor', 'moesy', 'american', 'lists', 'my-y-y-y-y-y', 'snake', 'knit', 'wear', \"ball's\", 'mayor_joe_quimby:', 'triple-sec', 'product', 'adopted', 'woodchucks', 'label', 'nobel', 'haws', 'civic', \"dad's\", 'access', 'brightening', 'fireball', 'ears', 'one-hour', 'bars', 'joking', 'shakespeare', 'poster', 'life', 'sent', 'calculate', 'manjula', \"world's\", 'unless', \"hell's\", 'enthusiasm', 'refinanced', 'stalin', 'carb', 'an', 'businessman_#1:', 'presses', 'popping', 'son', 'lorre', 'cent', 'mocking', 'nose', 'excuse', '91', 'besides', 'mint', 'professional', 'fishing', 'ghouls', 'hunky', 'holding', 'boozy', 'bliss', 'pretzels', 'wa', 'yammering', 'rip', 'dirt', 'peach', 'follow', 'catholic', 'computer_voice_2:', 'mac-who', 'proves', 'radiator', 'modern', 'state', 'starts', 'mail', 'electronic', 'man_with_crazy_beard:', \"'your\", 'investigating', 'grabs', 'buffet', 'riveting', 'force', 'realize', 'junkyard', 'outta', 'knowingly', 'neither', 'way', 'fold', \"swishifyin'\", 'uninhibited', 'spellbinding', \"choosin'\", 'runners', 'easter', 'crank', 'photo', 'sagely', 'duty', 'sat', 'gimmicks', 'moved', 'cigarettes', 'yup', 'curse', 'strictly', 'intruding', 'un-sults', 'wishes', 'homeless', 'well-wisher', 'wagering', 'bauer', 'cable', 'sotto', 'temper', 'einstein', 'dee-fense', 'wussy', 'foam', 'sweden', 'roy', 'soot', 'exasperated', 'hot', 'creature', 'oooh', 'hounds', 'brainheaded', 'diets', 'frink', 'louie:', 'marry', 'fighting', 'barn', 'drapes', 'updated', 'insulted', 'casting', \"watchin'\", 'cheesecake', 'sadder', \"takin'\", 'fox_mulder:', 'sponsoring', 'place', 'choices:', 'faith', 'exits', 'ralphie', 'appear', 'clears', 'song', 'manjula_nahasapeemapetilon:', 'wisconsin', 'pants', 'tatum', 'breathless', 'life-sized', 'contented', 'jasper_beardly:', 'dutch', 'cologne', 'federal', 'hi', 'monorails', 'administration', \"spyin'\", 'more', 'hall', 'games', 'need', 'clientele', 'erasers', 'transfer', 'president', 'items', 'peter_buck:', 'iran', 'underwear', 'world', 'fires', 'utensils', 'gold', 'beep', 'meteor', 'unsourced', 'warn', \"when's\", 'leans', 'video', 'unforgettable', 'helicopter', 'alone', 'suburban', 'politician', 'waist', 'reactions', 'pews', 'lenny_leonard:', 'warranty', 'show-off', 'sitar', 'jay:', 'nickels', 'apply', 'kneeling', 'supposed', 'passports', 'fatso', 'oh', 'takes', 'moe-lennium', 'flush-town', 'ivanna', 'bag', 'hundred', 'in-ground', 'kenny', 'italian', 'dregs', 'paris', 'boxing', \"fallin'\", 'just', 'charged', 'rascals', 'hot-rod', 'glee', 'paparazzo', 'preparation', 'yo', 'everyone', 'rom', 'orphan', 'grimly', 'clearly', 'boyfriend', 'build', 'offshoot', \"someone's\", 'snapping', 'rat', 'sharps', 'sneeze', 'nineteen', 'average-looking', 'shrieks', 'showered', 'tester', 'mug', 'guys', '7g', 'firing', 'two-drink', 'experienced', 'captain', 'bible', 'menacing', 'return', 'population', 'charming', 'ignoring', \"readin'\", 'maman', 'hooters', 'finance', 'reed', 'navy', 'drivers', 'option', 'nickel', \"maggie's\", 'chateau', 'adrift', 'from', 'mimes', 'exception:', 'goodwill', 'savvy', 'gift:', 'schnapps', 'folk', 'ready', 'serious', \"comin'\", 'agent_miller:', 'her', 'thoughtless', 'flayvin', 'fustigation', 'cure', 'schmoe', 'david_byrne:', 'indigenous', 'apron', 'handing', 'tragedy', \"mother's\", 'shard', 'mostly', 'kitchen', 'certainly', 'memories', 'lennyy', 'stopped', 'distaste', 'cuddling', 'colossal', \"pickin'\", 'guinea', 'mixed', 'given', 'cocoa', 'rainbows', 'homesick', 'all-star', 'quiet', 'rat-like', 'gayer', 'boxer:', 'inserted', 'asked', 'list', 'nightmare', 'porn', 'ends', 'reconsidering', 'whisper', 'dizzy', 'snout', 'proposition', 'achebe', 'tv_announcer:', 'fifth', 'years', \"mecca's\", 'completing', 'plan', 'bums', 'behind', 'disgrace', 'mel', 'near', 'clown', 'hose', 'macgregor', 'wazoo', 'drunk', 'lying', 'surprising', 'yello', 'blown', 'apulina', 'everywhere', 'paintings', 'lager', 'bust', 'done:', 'dilemma', 'folks', 'separator', 'toys', 'complaining', 'tyson/secretariat', 'mexicans', 'shortcomings', 'hate', 'key', 'permitting', 'usually', 'tenuous', 'ech', 'here-here-here', 'insults', 'wowww', 'therefore', 'chick', 'scully', 'compete', 'raking', 'upbeat', 'able', 'cricket', 'grab', 'routine', 'settles', 'recently', 'sending', 'hostile', 'root', 'stocking', 'hemoglobin', 'pope', 'voted', 'chug-a-lug', 'beautiful', 'subscriptions', 'paints', 'isle', 'dirge-like', \"nothin's\", 'noble', 'loud', 'disappeared', 'full', \"meanin'\", \"phone's\", 'lame', 'measurements', 'taxi', 'sucker', 'polygon', 'exact', \"handwriting's\", 'glyco-load', 'phrase', 'bathing', 'not', 'presumir', 'delivery_man:', 'fired', 'nordiques', 'followed', 'kindly', 'weapon', 'factor', 'disappointed', 'settlement', 'cheering', 'please/', 'rented', 'bender:', \"what'll\", 'mellow', 'channel', 'cuckoo', 'jerry', 'whaaaa', '1-800-555-hugs', 'dessert', '_hooper:', 'nothing', 'film', 'than', 'woulda', 'cause', 'bite', 'byrne', 'pirate', 'invite', 'snorts', 'polls', 'saga', 'dealer', 'nein', 'week', 'booze', 'vacuum', \"costume's\", 'candles', 'almond', \"larry's\", 'ugly', 'conspiratorial', 'richer', 'brassiest', 'nasty', 'billion', 'taps', 'ball', 'bugging', 'divine', 'casual', 'perfunctory', 'mic', 'heads', 'saving', 'month', 'stirrers', 'santa', 'thirsty', 'ore', 'passes', 'freed', 'tons', 'aw', 'payday', 'amazing', 'broad', 'pause', 'prices', 'begin', \"life's\", 'drift', \"ol'\", 'tax', \"what're\", 'planted', 'kako:', 'sir', 'aggie', 'peanut', 'off', 'dana_scully:', 'potato', 'hiding', 'adult_bart:', 'hundreds', 'vampire', 'hunka', 'wudgy', 'singing/pushing', 'dashes', 'beating', 'selma', 'natural', 'traditions', 'obvious', 'idealistic', 'bragging', 'gary_chalmers:', 'funny', 'voyager', 'wha', 'support', 'hail', 'manager', 'incredulous', 'push', 'pugilist', 'eva', 'coal', 'jewelry', 'tiny', 'audience:', 'turn', 'test-lady', 'grammys', 'ram', 'cannot', 'perfected', 'item', 'wooooo', 'typing', 'wreck', 'two-thirds-empty', 'thoughts', 'rip-off', 'gulliver_dark:', 'sedaris', 'drunkenly', 'customers-slash-only', 'attached', 'startled', 'lib', 'drinking', 'nibble', 'dreams', 'liability', 'best', 'bowled', 'stunned', \"this'll\", 'balls', 'airport', \"'til\", 'by', 'rag', 'castle', 'sucks', 'clock', 'good', 'mobile', 'mike', 'saget', 'careful', 'colorado', 'scum', 'portentous', 'fella', 'want', 'hook', 'darts', 'gee', 'k', 'world-class', 'mugs', 'kiss', 'bachelorette', 'bitterly', 'helpful', 'incapable', 'crew', 'embarrassed', 'encouraged', 'chip', 'bon-bons', 'schabadoo', 'breakdown', 'employment', 'unlocked', 'thank', 'detective_homer_simpson:', 'ura', 'starla', 'calmly', 'carney', 'flashbacks', \"santa's\", 'except', 'windowshade', 'pointy', 'wolfe', 'belly-aching', 'ingredient', 'etc', 'choke', 'bags', \"he'll\", 'tablecloth', 'taken', 'espn', 'radiation', \"i'll\", 'pity', 'selling', 'alfred', 'welcome', 'probably', 'badmouth', 'sugar', 'consciousness', 'forgive', 'fdic', 'gal', 'growing', 'clearing', 'convenient', 'space', 'thnord', \"soakin's\", 'bellyaching', 'totalitarians', 'moonlight', 'professor', 'compliments', 'michelin', 'launch', 'stinky', 'daddy', 'expired', \"tinklin'\", 'stats', 'sixteen', 'attractive', 'tommy', 'led', 'absorbent', 'fat-free', 'ancient', 'pageant', 'hawaii', 'gas', 'bad', 'specializes', 'ha-ha', 'sesame', 'je', 'shutting', 'older', 'democrats', 'neighborhood', 'series', 'dearest', 'ordered', 'dictator', 're-al', 'absolut', 'missing', 'dames', 'heart-broken', 'putting', 'sounded', 'vance', 'twelveball', \"team's\", 'banks', 'white', 'last', 'weak', \"'ere\", 'victim', 'unison', 'normal', 'lemme', 'vigilante', 'decadent', 'relaxed', 'later', 'gossipy', 'arse', 'pointed', 'korea', 'inside', 'advice', 'charm', 'clips', 'tearfully', 'super-tough', 'hanh', 'anthony_kiedis:', 'glowers', 'bless', 'slap', 'comedy', 'manipulation', 'mickey', 'ha', 'here', 'salt', 'grin', 'cleaned', 'announcer:', 'aer', 'smallest', 'sacrifice', 'pitcher', \"breakin'\", 'future', 'flew', 'mouth', 'needy', 'wooden', 'bam', 'rig', 'flying', 'had', 'paying', 'wrecking', 'comedies', 'neat', 'competitive', 'worried', 'squishee', 'booking', 'emporium', 'blissful', 'pushing', 'grave', 'reader', 'beer:', 'twin', 'breaks', 'giving', 'embarrassing', 'lofty', 'winning', 'mansions', 'shrugs', 'joint', 'cat', 'terrified', 'delighted', 'competing', 'average', 'belts', 'impress', 'mason', 'billy_the_kid:', 'badge', 'species', 'victory', 'voters', \"man's\", 'foot', 'large', \"people's\", 'this:', 'tv_father:', 'sports_announcer:', 'boned', 'number', 'pretzel', \"startin'\", 'chug', 'rob', \"nothin'\", 'brilliant', 'reentering', 'fact', 'sloppy', 'thought_bubble_lenny:', 'fast-food', 'shells', 'sighs', 'dive', 'disappointment', 'hafta', 'yep', 'awwww', 'part-time', 'too', 'ga', 'fonzie', 'various', 'restaurants', 'ees', 'fixed', 'lay', 'widow', 'tow', 'bowling', 'flag', 'nasa', 'rueful', 'accident', 'tongue', 'relieved', \"mtv's\", 'bed', 'kwik-e-mart', 'itchy', 'sport', 'any', 'absentminded', 'star', 'hoping', 'kyoto', 'real', 'pockets', 'surprised', 'ineffective', 'shaking', 'burnside', 'anonymous', 'sleeping', 'great', 'falcons', 'treasure', 'town', 'barely', 'bottom', 'grim', 'augustus', \"talkin'\", 'sidelines', 'robbers', 'dum-dum', 'choose', 'said', 'movement', 'artist', 'pasta', 'pas', 'bartenders', 'thunder', 'soap', 'diving', \"who'da\", 'gonna', 'fast-paced', 'elaborate', 'sigh', 'incarcerated', 'huddle', 'bye', 'coat', 'worry', \"he's\", 'sink', 'confidentially', 'disturbing', 'answering', 'kirk', 'steak', 'camp', \"y'know\", 'semi-imported', 'aggravated', 'swine', 'gasps', 'coming', 'hems', \"tap-pullin'\", 'homer_simpson:', 'weekend', 'comment', 'fbi_agent:', 'take-back', 'brow', 'renew', \"somebody's\", 'without:', 'leonard', 'rules', 'leftover', 'onassis', 'sales', 'nope', 'adult', 'sanitation', 'mabel', 'lessons', 'watching', \"president's\", 'dungeon', 'soon', 'faced', 'spending', 'answered', 'amber', 'reaches', 'bupkus', 'pictured', 'a-b-', 'alls', 'wondered', 'chuck', 'richard:', 'event', 'carmichael', 'poetry', 'indeedy', 'stops', 'murmur', \"'morning\", 'murdoch', 'clipped', 'stab', 'pee', 'pyramid', 'enforced', 'cover', 'massive', 'examples', \"father's\", 'plastered', 'career', 'madonna', 'underbridge', 'yak', 'supply', 'mural', 'cavern', 'profiling', 'guff', 'deeply', 'hospital', 'bush', 'sweetly', 'door', 'palmerston', \"showin'\", 'walked', 'shreda', 'village', 'tomato', \"y'see\", 'norway', 'ballclub', 'boisterous', 'sketch', 'purse', 'margarita', 'horrors', 'tree_hoper:', 'stalking', 'lookalikes', 'sturdy', 'supports', 'newsweek', 'sisters', 'suspect', 'saved', 'boxcars', 'furry', 'pit', 'dry', \"squeezin'\", 'lenny:', 'tomorrow', 'please', 'guiltily', 'gabriel', 'declan_desmond:', 'cartoons', 'cab', 'little_man:', \"brady's\", 'lord', 'generally', \"bringin'\", 'anybody', \"jackpot's\", 'died', 'jeff_gordon:', 'hats', 'shesh', 'site', 'works', 'rupert_murdoch:', 'tease', 'beligerent', 'ping-pong', 'someone', 'thighs', 'ape-like', 'protecting', 'when-i-get-a-hold-of-you', 'buzz', 'universe', 'dads', 'boozer', 'safely', 'polite', 'non-american', 'british', 'alma', 'stagehand:', 'effects', 'brother', 'goblins', 'afloat', 'eightball', 'williams', 'peaked', 'alarm', 'france', 'bank', 'swings', 'baseball', 'skinner', 'duffman', 'ironed', 'whatcha', 'regulations', 'enter', 'disgracefully', 'job', 'junebug', 'family', 'begging', 'grants', 'valley', \"couldn't\", 'car', 'kinda', \"mo'\", 'shriners', \"shootin'\", 'kid', 'crap', 'ling', '脿', 'sweaty', 'bedtime', 'rutabaga', 'theme', 'pointless', \"stealin'\", 'coma', 'squabbled', 'x', 'heather', 'pinball', 'leaving', \"coffee'll\", 'between', 'homeland', 'william', 'shaved', 'mmm-hmm', 'covering', 'uglier', 'conditioners', 'shoot', 'washed', 'desire', 'nos', 'statue', 'guzzles', 'screw', 'complicated', 'breathalyzer', 'lotta', 'compressions', 'regulars', 'deeper', 'gave', \"buffalo's\", 'hungry', 'puffy', 'refund', 'enthused', 'deliberate', 'yea', 'ripper', 'could', 'nascar', 'ferry', 'flaming', 'eleven', 'hotenhoffer', 'sniper', 'mid-conversation', 'planet', 'limber', 'moe', 'flush', 'play/', 'searching', 'stood', 'divorced', 'spoon', 'forget-me-shot', \"narratin'\", 'stiffening', 'plucked', 'heh-heh', 'finding', \"cuckold's\", \"money's\", 'mechanical', 'jebediah', 'witty', 'stares', 'dumb', 'johnny_carson:', 'fortress', 'studio', 'course', 'crapmore', 'men:', 'highest', 'cletus_spuckler:', 'feels', 'trunk', 'jams', 'composer', 'meditative', 'shindig', 'penmanship', 'synthesize', 'marched', 'awesome', 'twice', 'lookalike', 'fat_in_the_hat:', \"b-52's:\", 'mock', 'there', 'lease', 'health_inspector:', 'contest', 'cooking', \"havin'\", 'enemy', 'reflected', 'left', 'supervising', 'vote', 'disappear', 'tender', 'hurting', 'wigs', 'heading', 'months', 'lou', 'contract', 'allow', 'gumbel', 'locklear', 'talkative', 'model', 'the_rich_texan:', 'it:', 'after', 'considering', 'consoling', 'zack', 'of', 'charlie', 'disgraceful', 'privacy', \"starla's\", 'flexible', 'curds', 'owns', 'um', 'approval', 'edna-lover-one-seventy-two', 'lee', 'package', 'ice', 'options', 'apart', 'arab_man:', 'exclusive:', 'contemplates', 'mine', 'cooler', 'limericks', 'your', 'occurrence', 'sideshow_bob:', 'per', 'rope', 'seven', 'broncos', 'ballot', 'brunswick', 'doreen:', 'shoe', 'contemptuous', 'cappuccino', 'seeing', 'since', 'remember', 'wienerschnitzel', 'presently', 'doreen', 'guy', 'came', 'deliberately', 'selfish', 'moments', '||leftparentheses||', 'endorsed', 'crow', 'happily', 'lingus', 'darn', 'applicant', 'guest', 'halfway', 'watered', 'beer-jerks', 'reptile', 'bono:', 'yap', 'insured', \"i'unno\", 'stick', 'ancestors', 'fiiiiile', 'was', 'therapist', 'cajun', 'page', 'calvin', 'reminded', 'starla:', 'ow', 'tomatoes', 'ear', 'twenty-nine', 'sudden', 'eighty-seven', 'gin', 'nobody', 'kissing', 'wipes', 'wikipedia', 'peppy', 'doctor', 'monroe', 'beached', 'swallowed', \"where's\", 'pian-ee', 'naturally', 'plaintive', 'me', 'binoculars', 'rug', 'familiar', 'handling', 'rude', 'unintelligent', 'kissingher', 'other_book_club_member:', 'creepy', 'doof', 'field', 'bouquet', 'tied', \"'round\", 'towed', 'isotopes', 'naked', 'edelbrock', 'super-genius', 'burger', 'slab', 'fish', 'jury', 'prefer', 'passion', 'outrageous', 'renders', 'iranian', 'suspiciously', 'wieners', 'does', 'wraps', 'anywhere', 'lise:', \"ma's\", 'out', 'thinks', 'eating', 'throats', 'low', 'cueball', 'spanish', 'distraught', 'murderously', 'continued', 'bleak', 'maggie', 'cookies', 'astrid', 'winded', 'pad', 'fondest', 'super', 'napkins', 'geez', 'waters', 'improved', \"'\", \"number's\", 'moon', 'special', 'ooo', 'let', \"dyin'\", 'throwing', 'orifice', 'wade_boggs:', 'trolls', 'anyway', 'wing', 'alcoholism', 'empty', 'germans', 'caricature', 'surgery', 'urban', 'bon', 'superdad', 'whatsit', 'thing:', 'heartless', 'neil_gaiman:', 'barflies', 'spied', 'listened', 'sleep', 'fast', 'officer', 'hockey-fight', 'full-bodied', 'easier', \"linin'\", 'forever', 'rims', 'demand', 'muffled', 'felt', 'sealed', 'measure', \"one's\", 'surgeonnn', 'ze-ro', 'flophouse', 'hat', 'recorded', \"hadn't\", 'neighbors', '50-60', 'manfred', 'inches', 'salary', 'cutest', 'oh-ho', 'clenched', 'compared', 'spacey', 'dump', 'natured', 'rusty', 'carolina', \"weren't\", \"o'problem\", 'himself', 'scooter', 'while', 'lousy', 'intelligent', 'starving', 'beanbag', 'bastard', 'ma', 'following', 'muhammad', 'stingy', 'installed', \"valentine's\", \"'evening\", 'museum', 'what-for', 'indifference', \"cont'd:\", 'regret', 'seemed', \"rentin'\", 'nerve', 'portuguese', 'citizens', 'mither', 'plans', 'chum', 'fuss', 'sweetheart', 'seamstress', 'am', 'hates', 'specialists', 'move', 'free', 'shoulders', 'famous', 'housework', 'bedbugs', 'throat', 'ignorant', 'to', 'mariah', 'be', 'inclination', 'discussing', 'musical', 'curiosity', 'scout', 'totally', 'trail', 'bought', 'aggravazes', 'farewell', 'self-satisfied', 'aunt', 'comforting', 'pajamas', 'ago', 'louder', \"tv'll\", 'freely', 'sexton', 'script', 'said:', 'alter', 'wham', 'seem', 'n茫o', 'alibi', 'quarter', 'strokkur', 'monday', 'law-abiding', 'boxers', 'twenty-six', 'certified', 'squeezed', 'methinks', 'coffee', 'atari', 'thirty', 'twenty', 'palm', 'chipper', 'tough', 'reads', 'shaggy', '3', 'brown', 'eyes', 'chicks', 'thirty-thousand', 'unbelievable', \"tryin'\", 'win', 'harder', 'hangover', 'monkeyshines', 'playhouse', 'toward', 'burning', 'partially', 'justice', 'lucinda', 'gut', 'fourteen:', 'buyer', 'defeated', 'beach', \"high-falutin'\", 'german', 'james', \"we're\", 'ali', 'multiple', 'load', 'powered', 'owe', 'help', 'energy', 'equal', 'exploiter', 'sangre', 'least', 'hawking:', 'modest', 'cans', 'lloyd:', 'harv', 'needs', 'camera', 'p', 'modestly', 'bras', 'clothespins', 'flanders:', 'assert', 'philosophical', 'scene', 'kissed', \"who'll\", 'sizes', 'late', 'knock', 'laughs', 'hydrant', 'socialize', 'aged', 'carpet', 'wearing', \"they'll\", 'unlike', 'shtick', \"listenin'\", 'recreate', 'creates', \"thing's\", 'sequel', 'point', 'oww', 'chips', 'mcstagger', 'kay', 'football', 'magnanimous', 'moe-heads', 'checking', \"tonight's\", 'icelandic', 'accurate', 'nightmares', 'slick', 'tropical', 'freak', 'falsetto', 'lenny', 'wishing', 'young_moe:', 'squeal', 'boo', 'proud', 'dash', 'kodos:', 'sensible', 'mall', 'spy', 'chinua', 'anxious', 'babies', 'extract', 'company', 'sieben-gruben', '2', 'wars', 'humanity', 'yourse', 'rife', 'mary', 'day', 'labor', 'multi-purpose', 'streetcorner', 'abercrombie', 'feld', 'gel', 'hated', 'character', 'bleacher', 'faulkner', 'throw', 'mouths', 'hired', 'managing', \"homer's_brain:\", 'snake_jailbird:', \"o'clock\", 'sue', 'combines', 'shirt', 'guilt', 'bookie', \"liberty's\", \"man'd\", 'mater', \"g'on\", 'hunter', 'trapping', 'simp-sonnnn', 'ziffcorp', 'so-called', 'pennies', 'flowers', 'sign', 'sabermetrics', 'ignorance', 'bubbles-in-my-nose-y', 'luv', 'the_edge:', 'loboto-moth', 'jacks', 'darjeeling', 'pip', 'regretful', 'host', 'send', 'agency', 'poet', 'mmm', 'jer', 'looking', 'outlook', 'railroads', \"car's\", 'infatuation', 'metal', 'slyly', 'elephants', 'feelings', 'minutes', 'xanders', \"ya'\", 'error', 'ah-ha', 'groan', 'happily:', 'naval', 'bar_rag:', 'releasing', 'sure', 'tow-talitarian', 'unattractive', 'raggie', 'deals', \"beer's\", 'explaining', 'fustigate', 'emergency', 'proposing', 'actor', 'beaumarchais', 'walks', 'team', 'poplar', 'that', 'capitol', '21', 'moans', 'plug', 'domed', 'scornful', 'thomas', \"ma'am\", 'self-made', 'overstressed', 'microphone', 'chase', 'apu', 'pathetic', 'steam', 'starve', 'blade', 'limited', 'relative', 'wuss', 'eat', 'are', 'hear', 'girl', 'bets', 'larry', 'skoal', 'brief', 'eventually', 'trouble', 'singers:', 'huhza', 'ruuuule', 'wash', 'charter', 'brawled', 'countryman', 'sing-song', 'gutenberg', 'allowance', 'wistful', 'handsome', 'fantastic', 'praise', 'nonchalant', 'ticket', \"thinkin'\", 'replaced', 'dating', 'stan', 'putty', 'conclude', 'dyspeptic', 'hairs', \"knockin'\", 'snake-handler', 'rugged', 'menlo', 'happens', 'gloop', 'candidate', 'fingers', 'against', 'european', 'all-all-all', 'grease', 'vampires', 'trees', 'hang', 'burp', 'puzzle', 'flash', 'health', \"wearin'\", 'maximum', 'disguised', 'buzziness', 'fellas', 'parasol', 'snitch', 'laughing', 'chinese', 'bill_james:', 'reviews', 'declare', 'raising', 'biggest', 'soup', 'inflated', 'shopping', 'public', \"i-i'm\", 'billiard', 'la', 'holiday', 'mudflap', 'hardwood', 'read:', 'smile', 'j盲germeister', 'shelbyville', 'small', 'wordloaf', 'sound', 'sets', 'city', 'feedbag', 'stagy', 'recipe', 'book', 'ask', 'chipped', 'choices', 'fears', 'register', 'irrelevant', \"somethin'\", 'eighty-three', 'ew', 'affectations', 'thumb', 'halloween', 'blossoming', 'liver', 'defected', 'audience', '/mr', 'nursemaid', 'suits', 'secret', 'mistresses', 'insensitive', 'orgasmville', 'mad', 'imaginary', 'bully', 'solo', 'lessee', 'it', 'having', 'meyerhof', 'lady', 'class', 'won', 'write', 'think', 'bottoms', 'stealings', \"kearney's_dad:\", 'cup', 'don', 'jelly', 'edgy', 'homer_', 'enterprising', 'reluctant', 'persia', \"dimwit's\", 'aims', 'drive', 'apology', 'corkscrews', 'ihop', 'and:', 'cursed', 'dropping', \"livin'\", 'backwards', 'play', 'phony', 'anti-intellectualism', 'quotes', 'attitude', 'knows', 'teenage_homer:', 'gallon', 'table', 'log', 'disillusioned', 'danish', \"pressure's\", 'pop', 'oopsie', 'self-esteem', 'another', 'spitting', 'investment', 'mole', 'bit', 'ugh', 'habitrail', 'settled', 'vanities', 'other', 'onto', 'shush', 'strains', 'videotaped', 'insurance', 'impending', 'seymour', 'certain', 'dignified', 'stored', 'scram', 'shows', 'switch', \"others'\", 'stillwater:', 'nation', 'dateline:', 'pepsi', 'solely', 'dumbass', 'toxins', 'gunter', 'called', 'favor', 'christian', 'fistiana', 'prejudice', 'veux', 'alky', '||comma||', 'fall', 'eight', 'cutting', 'territorial', 'thought_bubble_homer:', 'producers', 'college', 'crying', 'nail', 'gol-dangit', 'frogs', 'smuggled', 'confidence', 'grinch', 'looting', 'clapping', 'waking-up', 'button', 'blokes', 'dressing', 'clams', 'this', \"c'mon\", 'wall', 'screams', 'mm-hmm', 'kisses', 'passed', 'startup', \"family's\", 'tabs', 'commit', 'creeps', 'telling', 'butts', 'title', 'notice', 'phase', 'picked', '||period||', 'sustain', 'serum', 'sweet', 'girls', 'sacajawea', 'higher', 'eliminate', 'thanking', 'kahlua', 'material', 'presentable', 'decide', \"duff's\", 'innocence', 'longest', 'prince', '-ry', 'unfresh', 'warned', 'pouring', 'eighty-one', 'ollie', 'delivery_boy:', 'grey', 'krabappel', 'barbara', 'bad-mouth', 'writers', 'tolerance', 'thirty-nine', 'movies', 'carey', 'apartment', 'illegal', 'hushed', 'kemi:', 'branding', 'healthier', 'cozies', 'tummies', 'developed', 'coughs', \"renovatin'\", 'smithers', 'cigars', 'hibbert', 'red', 'sprawl', 'made', 'brockman', 'words', 'malfeasance', 'contractors', 'sucking', 'satisfaction', 'technical', 'resenting', \"i-i'll\", 'reporter', 'kemi', 'ahem', \"challengin'\", 'coward', 'breath', 'skinheads', 'poisoning', 'standing', 'mind', 'cash', 'waylon', 'upgrade', 'espousing', '70', 'coy', 'grind', 'arrested:', 'shelf', 'timbuk-tee', \"that'll\", 'puke-holes', 'tolerable', 'face', 'apu_nahasapeemapetilon:', \"somethin's\", 'sen', \"everyone's\", 'rub', 'bum:', 'hangout', 'proof', 'feet', 'nor', 'karaoke', 'everybody', 'diddilies', 'parents', 'dramatically', 'close', \"today's\", 'congratulations', 'certificate', 'glasses', 'opening', 'personal', \"barney's\", 'splash', 'boring', 'thirty-three', 'killing', 'larson', 'considers', 'barney-shaped_form:', 'shaky', 'unlucky', 'tones', 'story', 'sternly', 'colonel:', 'helllp', 'mate', 'changes', 'briefly', 'frankly', 'counter', 'cries', \"sat's\", 'though:', 'insecure', 'rapidly', 'royal', 'trip', \"smackin'\", 'mistake', 'photos', 'contemplated', 'moron', 'fierce', 'chuckle', 'stupid', 'own', 'my', 'swishkabobs', 'chain', 'yours', 'america', 'lighter', 'bartending', 'hm', 'sunk', 'until', 'duel', 'nachos', 'saturday', \"getting'\", \"rustlin'\", 'tall', 'acceptance', 'ohh', 'still', 'act', 'dishonor', 'clandestine', 'thanks', 'groveling', 'combine', '_kissingher:', 'nigerian', 'lift', 'interrupting', 'johnny', 'john', 'text', \"depressin'\", \"coaster's\", 'whiny', \"moe's_thoughts:\", 'granted', 'difficult', 'stevie', 'loved', 'answers', 'grand', 'de', 'restroom', 'cecil_terwilliger:', 'morose', 'wally:', 'gin-slingers', 'confession', 'beards', 'killer', 'precious', 'ford', 'sniffles', 'smile:', 'fourth', 'ah', 'piano', 'predictable', 'foibles', 'keys', 'crisis', \"drinkin'\", 'sec_agent_#2:', 'forget-me-drinks', 'light', 'examines', 'shred', 'ya', 'she-pu', 'interesting', 'voicemail', 'dipping', 'stay', \"hobo's\", 'cecil', 'fell', 'quadruple-sec', 'jumping', 'majesty', 'gums', 'cosmetics', 'insightful', \"isn't\", 'woo', \"spiffin'\", 'spare', 'office', 'kramer', 'bagged', 'steampunk', 'process', 'phlegm', \"drivin'\", 'fence', 'coherent', 'degradation', 'wasting', \"stabbin'\", 'handwriting', 'eighteen', 'sugar-free', 'coined', 'trivia', 'have', 'compare', 'negative', 'causes', 'rockers', 'wednesday', 'peabody', \"disrobin'\", 'comfortable', 'clincher', 'a-a-b-b-a', 'morning', \"bar's\", 'kirk_van_houten:', 'sight', 'infor', 'quit', 'thrilled', 'senators:', 'remembering', 'getting', 'lugs', 'use', 'right-handed', 'full-blooded', 'insist', 'sodas', 'relationship', 'milhouse', 'mumble', 'strongly', 'brag', 'much', 'lady_duff:', 'scared', 'pickle', 'cross-country', 'activity', 'agree', \"time's\", 'seas', 'academy', 'ireland', 'cocks', 'talked', 'frankenstein', 'excavating', 'stayed', 'predecessor', 'single-mindedness', 'reluctantly', 'manage', 'aid', 'catching', 'defiantly', 'ned_flanders:', 'santeria', 'cloudy', 'bread', 'agreement', 'south', 'dumb-asses', 'odor', 'give', \"man's_voice:\", 'girlfriend', 'who', 'ho-la', 'hyahh', 'highball', \"poisonin'\", 'haplessly', 'summer', 'selma_bouvier:', 'did', 'prank', 'femininity', 'come', 'wanna', 'botanical', 'worst', 'check', 'fat_tony:', 'equivalent', 'kentucky', 'possessions', 'shuts', 'midnight', 'childless', 'appendectomy', 'thesaurus', 'adjourned', 'kidnaps', 'without', 'boxer', 'edna', 'alfalfa', 'teacher', \"what'sa\", 'whispered', 'popped', 'pocket', 'advance', 'five-fifteen', 'butter', 'bonfire', 'imagine', 'international', 'deadly', 'crushed', 'wells', 'restless', 'enhance', 'jerking', \"something's\", 'crummy', 'wings', 'steely-eyed', 'crowds', 'peppers', 'read', 'needed', 'moonnnnnnnn', 'grammy', 'student', 'recall', 'annus', 'puzzled', 'official', 'hop', 'handed', 'boston', 'radio', 'morning-after', 'nah', 'miracle', 'cruiser', 'players', 'dea-d-d-dead', 'trusted', 'hmmmm', 'barney_gumble:', 'smug', 'rhode', 'picky', 'intimacy', 'signal', 'belly', \"lovers'\", 'ocean', 'de-scramble', 'ho-ly', 'ninth', 'maya', 'barber', 'popular', 'community', 'hearse', 'cowboy', 'borrow', 'ladies', 'gardens', 'eurotrash', 'capitalists', 'yellow-belly', 'friend', 'got', \"doctor's\", 'scent', 'buddy', 'chanting', 'wild', 'cushions', 'points', 'urine', 'shower', 'tv_daughter:', 'pulled', 'something', 'perverse', 'abe', 'anarchy', 'wacky', 'shut', 'elect', 'winch', 'playful', 'pal', 'ticks', 'brought', 'gentle', 'war', 'he', 'champion', \"heat's\", 'cupid', 'forgotten', 'lis', 'industry', 'assassination', '_zander:', 'nervous', 'texas', 'eye', 'pudgy', 'stinks', 'winnings', 'solves', 'albeit', 'take', 'ding-a-ding-ding-ding-ding-ding-ding', 'low-blow', 'longer', 'wally', 'procedure', \"o'reilly\", \"tomorrow's\", 'mister', 'bites', 'ails', 'springfield', 'police', 'samples', 'knocked', 'cranberry', 'babe', 'bigger', 'grandmother', 'psst', 'walther_hotenhoffer:', 'goods', 'canyoner-oooo', 'pets', 'doooown', \"aren'tcha\", 'lovelorn', 'agent', 'dory', 'skirt', 'married', 'eye-gouger', 'capuchin', 'generosity', 'accepting', 'cough', 'drinking:', 'sly', 'deny', 'couch', 'justify', 'faiths', 'yell', 'broken', 'ass', 'gargoyle', 'attach', 'his', \"how're\", 'dreary', 'known', 'bret', 'milhouse_van_houten:', 'spot', 'worldview', \"kiddin'\", 'prison', 'attention', \"blowin'\", 'puke', 'giggle', 'reach', 'opportunity', 'maybe', 'delightful', 'drink', 'fletcherism', 'quebec', 'represent', 'environment', 'fumes', 'center', 'peeping', 'floating', 'bar', 'corn', 'spent', 'plants', 'wife', 'admit', 'plus', 'annoying', 'wears', 'in', 'again', 'sponge', 'doug:', 'rafters', 'ninety-six', 'jeter', 'action', 'poetics', 'helen', 'fresh', 'baby', 'informant', 'sidekick', 'barkeep', 'morlocks', '_timothy_lovejoy:', 'otherwise', \"shouldn't\", 'hurts', 'teen', 'mrs', 'pronounce', 'funds', 'para', \"washin'\", 'feat', 'scrutinizes', 'exhaust', 'forty', 'founded', 'inspire', 'counting', 'puts', 'hooky', 'dismissive', 'room', 'dae', \"ain't\", 'paramedic:', 'snort', 'texan', 'continuum', 'forehead', 'securities', 'all', 'tenor:', 'poor', \"friend's\", 'frosty', 'babar', 'short_man:', 'ne', \"games'd\", 'painting', 'never', 'advertising', 'coins', 'rolled', 'man_with_tree_hat:', 'assistant', 'difference', 'corporation', 'barf', 're:', 'depository', 'odd', 'device', 'foundation', 'tracks', 'bees', 'hardhat', 'bring', 'tabooger', 'ought', 'stupidly', 'allegiance', 'fighter', 'internet', 'bottomless', 'cannoli', 'noise', 'exactly', 'owned', 'boneheaded', 'fiction', 'guts', \"tellin'\", 'macaulay', 'admiration', 'looked', 'killed', 'infiltrate', 'effervescent', 'verdict', 'permanent', 'poured', 'step', 'chest', 'brother-in-law', 'whining', 'kinds', 'pontiff', 'tapered', 'bachelor', 'earrings', 'love', 'felony', 'draw', 'indeed', 'bottles', 'sun', \"calf's\", 'cheers', 'gun', 'illegally', 'reasonable', 'weary', 'convinced', 'julep', 'alternative', 'ivory', 'glorious', 'total', 'clothespins:', 'diapers', 'plums', 'heck', 'virile', 'cab_driver:', 'yeah', 'bret:', 'carlson', 'coupon', 'birth', 'ominous', 'spamming', 'survive', 'lovejoy', 'rebuttal', 'reunion', 'floor', 'injury', 'enthusiastically', 'storms', 'complaint', 'press', 'kills', 'anniversary', 'heartily', 'high-definition', \"guy's\", 'happy', 'churchill', 'hottest', 'jerk-ass', 'venture', 'over-pronouncing', \"you'll\", 'chili', 'joke', 'jackson', 'ducked', 'type', 'sensitivity', 'strain', 'trick', 'offensive', 'maitre', 'steaming', 'gift', 'chairman', 'lifters', 'crunch', 'knuckle-dragging', 'pitch', 'hooray', 'most', 'phasing', 'disturbance', 'speech', 'ratio', 'important', 'foil', 'full-time', 'speaking', 'owner', 'purveyor', 'th', 'muscles', '||rightparentheses||', 'aziz', 'murdered', 'pink', 'saying', 'yet', 'moon-bounce', \"yesterday's\", 'books', 'bronco', 'elves:', 'losers', 'england', 'har', 'noggin', 'dan_gillick:', 'spreads', 'make:', 'dog', 'pipes', 'jump', 'polenta', 'tired', 'affects', \"tony's\", 'goldarnit', 'vulgar', 'break-up', 'ripped', 'misfire', 'filed', 'pickled', 'cousin', 'stink', 'karaoke_machine:', 'ads', \"moe's\", 'minute', \"game's\", 'ruby-studded', 'sorts', 'middle', 'tank', 'zinged', 'lainie:', 'watched', 'exited', 'heart', 'lush', 'tribute', 'wholeheartedly', 'hell', 'whole', 'authorized', 'spectacular', 'ultimate', 'gumbo', 'worthless', 'hustle', 'slugger', 'hope', 'y-you', 'sanitary', 'adventure', 'publish', 'sympathetic', 'othello', 'sitting', 'determined', 'order', 'punkin', 'sweater', 'flower', 'other_player:', 'bunch', 'crazy', \"you'd\", 'spit', 'al', 'windshield', 'drains', 'zeal', 'sauce', 'anything', 'dude', 'jacques', 'catty', 'grains', 'racially-diverse', 'corkscrew', 'knife', 'burt', 'arrived', 'splendid', 'kadlubowski', 'medieval', 'hopeful', 'pancakes', 'explanation', \"what'd\", 'icy', 'swigmore', 'gay', 'disaster', 'stickers', 'giggles', 'truck', '_burns_heads:', 'syndicate', 'symphonies', 'stinger', 'confidential', 'luxury', 'view', 'silence', 'started', \"now's\", 'notorious', 'pain', 'beast', 'freshened', 'annie', 'chic', 'sucked', 'sec_agent_#1:', 'will', 'dropped', 'brain', 'less', 'struggling', 'delts', 'running', 'laughter', 'forecast', 'faded', 'fills', 'appeals', 'wine', 'slaves', 'mystery', 'exultant', 'quimby', '10:15', 'smooth', 'chub', 'gentles', 'stays', 'go-near-', 'practically', 'feast', 'code', 'knives', 'realized', 'artie', \"liftin'\", 'shill', 'today/', 'memory', 'pharmaceutical', 'slop', 'yoink', 'irs', 'grumbling', 'flashing', 'ref', 'smokes', 'referee', 'th-th-th-the', 'leave', 'polishing', 'friday', 'beat', 'combination', 'chocolate', 'weep', 'dies', 'cocking', 'libraries', 'troll', 'these', 'grope', 'disappointing', \"tester's\", 'darkest', 'punching', 'lose', 'damn', \"america's\", \"poundin'\", 'fry', 'holds', 'young', 'sea', 'stacey', 'snow', 'rome', 'waste', 'problems', 'suddenly', 'vegas', 'earth', 'beard', 'carl_carlson:', 'private', 'background', 'suspicious', 'shaken', 'like', 'quitcher', 'collateral', 'moe_szyslak:', 'sampler', 'states', 'dennis_conroy:', 'uncle', 'newly-published', 'cheryl', 'thoughtfully', 'barney-type', 'wins', 'ambrosia', 'aquafresh', \"children's\", \"must've\", 'ehhhhhhhhh', 'seconds', 'doors', 'piece', 'male_singers:', \"can't-believe-how-bald-he-is\", 'swimmers', 'maintenance', 'rid', 'barkeeps', 'line', 'provide', 'crawl', 'brain-switching', 'spread', 'hillary', 'whose', 'jovial', 'charity', 'pigtown', 'mini-dumpsters', '1973', 'ken:', 'chunky', 'violations', 'refresh', 'go', 'idioms', 'immiggants', 'compadre', 'dateline', 'allowed', 'premise', 'ye', 'fight', 'onions', 'whatchacallit', 'change', 'henry', 'renee', 'changed', 'lily-pond', 'hero-phobia', 'people', 'eww', 'manuel', 'forbids', 'sloe', \"donatin'\", 'grenky', 'grandiose', 'aidens', 'fun', 'better', 'specified', 'jobs', 'deli', 'highway', 'prints', 'project', 'bloodball', 'urge', 'pantsless', \"wasn't\", 'brick', 'lead', 'valuable', 'diet', '_eugene_blatz:', 'cleaning', 'produce', 'abcs', 'earlier', 'happiness', 'perking', 'inning', 'unfair', 'hour', 'geysir', 'shoots', 'gentlemen', \"puttin'\", 'dark', 'yesterday', 'nash', 'thorough', 'sagacity', 'simon', \"where'd\", 'over', 'grammar', 'neck', 'entertainer', 'terror', 'station', 'donut-shaped', 'pride', 'eighty-six', 'guide', 'tapestry', 'beefs', \"it'll\", 'housewife', 'tune', 'uses', 'working', 'sale', 'sees', \"hangin'\", 'distance', 'concentrate', 'attraction', 'watashi', 'hiring', 'guttural', 'whoops', 'tips', 'typed', 'premiering', 'helping', 'teenage_bart:', 'schizophrenia', 'grocery', 'nauseous', 'tying', 'cheered', 'fireworks', 'nantucket', 'hans:', 'romance', 'fresco', 'links', 'heavyweight', 'protesting', 'aging', 'peeved', 'ton', 'benefits', 'princesses', 'fatty', 'sunny', 'fortensky', \"plaster's\", 'dozen', 'wang', 'heaving', 'tie', 'finger', 'expecting', 'barter', 'bart_simpson:', 'a', 'poison', 'for', 'beginning', 'sorry', 'woooooo', 'brewed', 'distract', 'gimme', 'band', 'alec_baldwin:', 'oughta', 'perch', 'smitty:', 'asleep', 'extinguishers', \"town's\", \"fryer's\", \"school's\", 'grub', 'ringing', 'punch', 'rule', 'glummy', 'malted', 'bunion', 'saucy', 'hemorrhage-amundo', 'hoagie', 'slurred', 'twins', 'fragile', 'midge', 'email', 'often', 'took', 'dawning', 'tooth', 'sooner', 'hunger', 'dealie', 'machine', 'raise', 'spender', 'drank', 'license', 'refreshingness', 'freaky', 'lazy', 'evergreen', 'juke', 'prettiest', 'due', 'touch', 'friendly', 'money', 'dumbest', 'open-casket', 'rubbed', 'cracked', 'numeral', 'language', \"'tis\", 'reaction', 'mexican_duffman:', 'shareholder', 'drives', 'fix', 'bald', 'promotion', 'things', 'choked-up', 'strawberry', 'curious', 'east', 'buried', 'stuff', 'plane', '||quotationmark||', 'kinderhook', 'midge:', 'safe', 'testing', 'vincent', 'comic', 'bulked', 'aristotle:', 'sing', 'feminist', 'hears', \"cupid's\", 'drawn', 'alright', 'massage', 'julienne', 'ditched', 'terrific', 'kings', 'planned', 'commanding', 'sugar-me-do', 'closes', 'homer_doubles:', 'jail', 'gentleman:', 'stern', 'invented', 'funniest', 'housing', 'executive', 'danny', 'laney_fontaine:', \"fine-lookin'\", 'sponge:', 'ridiculous', 'duffed', 'turning', 'unfortunately', 'beans', 'pleasant', 'pulls', 'anyhoo', '_julius_hibbert:', '250', 'three-man', 'u', 'coyly', 'sail', 'round', 'mitts', 'barflies:', 'admirer', 'declan', 'been', 'gary:', 'suing', \"callin'\", 'family-owned', 'bumped', 'ahead', 'children', \"neat's-foot\", 'edge', 'night', 'heaven', \"feelin's\", 'squashing', 'quimbys:', 'soaked', 'intriguing', 'furious', 'message', 'finally', 'scrubbing', 'lodge', 'linda_ronstadt:', 'milk', 'sperm', 'tickets', 'booth', 'manboobs', 'superpower', 'acquitted', 'chug-monkeys', 'nuts', 'sky', 'happened', 'dollar', 'very', 'attractive_woman_#1:', 'sobs', 'gore', 'robin', 'eyed', 'headhunters', 'oblongata', 'partners', 'talk-sings', 'face-macer', 'bumbling', 'else', 'fica', 'expect', 'whistles', 'stones', 'wishful', 'lottery', 'sinkhole', 'bar-boy', 'figure', 'envy-tations', 'cowboys', 'delivery', 'sack', \"nick's\", 'daughter', 'con', 'crystal', 'bee', 'gangrene', 'propose', 'doing', 'fondly', 'golden', 'reading', 'statistician', 'moolah-stealing', 'eats', 'anymore', 'refreshment', 'stretch', 'layer', \"workin'\", 'diamond', 'patterns', 'michael_stipe:', 'lime', 'lobster-based', 'along', 'telegraph', 'hey', 'bumblebee_man:', 'fink', 'amber_dempsey:', 'motorcycle', 'r', 'fake', 'thirty-five', 'excellent', 'hangs', 'optimistic', 'angel', 'el', 'monster', 'influence', 'name:', 'reckless', 'coms', 'motor', 'four', \"boy's\", 'couple', 'add', 'also', 'diablo', 'supplying', 'squeeze', 'organ', 'resolution', 'wh', 'sad', 'herself', 'wound', 'cobra', 'lady-free', 'susie-q', \"bashir's\", 'yard', 'quite', 'sissy', 'life:', \"enjoyin'\", 'thirteen', 'judges', 'desperate', 'suit', \"don'tcha\", 'is:', 'wheels', 'card', 'sharity', 'horror', 'newspaper', 'brains', \"makin'\", 'dials', 'intervention', \"lookin'\", 'occupied', 'you-need-man', 'cheer', 'nitwit', 'early', 'ones', 'cruel', 'gags', 'nooo', 'bolting', 'offa', 'dumbbell', 'jackpot-thief', 'seen', 'enlightened', 'selective', \"should've\", 'religious', 'twerpy', \"stayin'\", 'instantly', 'wow', 'grateful', 'salvation', 'crowned', 'covers', 'smiles', 'shorter', 'speak', 'woo-hoo', 'rock', 'lucius', \"idea's\", 'whenever', 'barney', 'mayor', 'refiero', 'sitcom', 'fumigated', 'remaining', 'legs:', 'getcha', 'father', 'jig', 'drop-off', 'rhyme', 'army', 'assume', 'ebullient', 'additional-seating-capacity', 'harv:', 'year', 'statues', 'indicates', 'puke-pail', 'snackie', 'lou:', 'rash', 'shakes', 'signed', 'suicide', 'papa', 'wore', 'wobble', 'pronto', 'cap', 'knees', 'stars', 'firmly', 'amiable', \"waitin'\", 'days', 'miles', 'elmer', 'gotta', 'lowers', 'indecipherable', 'slow', 'spotting', 'break', 'vengeance', 'bloodiest', 'prayer', 'vulnerable', \"gettin'\", 'municipal', 'chained', 'endorsement', 'located', 'friends', 'sweetie', 'ring', 'quarry', 'joining', 'weirder', 'long', 'scratcher', 'scruffy_blogger:', 'senator', 'trench', 'glum', 'quietly', 'nonsense', 'tasty', 'suspenders', 'seminar', \"spaghetti-o's\", 'proudly', 'impatient', 'lucius:', 'kl5-4796', 'up', 'playoff', 'wrap', 'studied', 'unavailable', \"writin'\", 'bleeding', 'cream', 'california', \"we'd\", 'oblivious', 'reached', 'thrown', 'wildfever', 'jack_larson:', 'self-centered', 'shove', 'itself', 'hah', \"kids'\", 'spite', 'sobriety', 'soul-crushing', 'salad', 'zone', 'aside', 'dinner', 'promised', 'expose', 'wipe', 'tinkle', 'thousand-year', 'common', 'endorse', 'drown', 'ideas', 'joined', 'patented', 'oddest', 'edner', 'luckiest', 'bedridden', 'busiest', 'bright', 'deal', 'application', 'rage', 'plum', 'crowd', 'getaway', 'uh', 'gimmick', 'keeping', 'u2:', 'brockelstein', 'shotgun', 'hurt', 'based', 'drollery', 'wrestle', 'savagely', 'woe:', 'decency', 'paper', 'luck', 'helps', 'crestfallen', 'so-ng', 'get', 'lighting', 'plant', 'inspired', 'superhero', \"plank's\", \"'pu\", 'broke', 'na', 'above', 'liser', 'sketching', 'fbi', 'golf', 'steel', 'ingrates', 'ayyy', 'straining', 'lock', 'koi', 'angrily', 'enough', 'declared', 'whim', 'mull', 'upsetting', 'kool', 'as', 'continuing', 'friendship', 'oof', 'rent', 'sincerely', 'shall', 'tip', 'us', 'motel', \"monroe's\", 'rotch', \"pope's\", 'cop', 'ruled', \"what's\", 'jar', 'aged_moe:', 'wasted', 'car:', 'caused', 'grabbing', 'faint', 'unkempt', 'championship', 'sideshow_mel:', 'amends', 'donuts', 'picnic', 'top', 'taste', 'depressed', 'cheat', 'watch', 'wish', 'unhook', 'actually', 'genuinely', 'alva', 'tasimeter', \"bein'\", 'evils', 'runt', \"snappin'\", 'spits', 'stamp', 'olive', 'outlive', \"'er\", 'rods', 'novelty', \"neighbor's\", 'shoulder', 'swooning', 'mild', 'four-star', 'slip', 'slurps', 'payments', 'george', 'drop', 'angry', \"ridin'\", \"chewin'\", 'secrets', 'monkey', 'soul', 'stagey', 'thought', 'cerebral', 'dammit', 'gregor', 'nfl_narrator:', 'terminated', 'flown', 'forty-two', 'sheepish', 'beer-dorf', 'worldly', '14', 'squirrel', 'minors', 'adequate', 'sass', 'exquisite', 'y', 'idiot', 'uh-oh', 'western', \"england's\", 'gheet', 'away', 'jazz', 'criminal', 'find', 'thousand', 'pay', 'railroad', 'pin', 'county', 'gambler', \"i'm-so-stupid\", 'pills', 'limits', 'irish', 'b', 'al_gore:', 'drug', 'fit', 'toms', 'slender', 'chauffeur', 'visas', 'sacrilicious', 'squirrels', 'mexican', 'stationery', 'named', 'hyper-credits', 'spilled', 'st', 'nigel_bakerbutcher:', 'can', 'consider', 'fire', 'tv_husband:', 'concerned', 'tee', 'bannister', 'husband', 'bride', 'greatest', \"'cept\", 'lachrymose', 'mayan', 'safer', 'bulletin', 'perplexed', 'lungs', 'tsking', 'surprise', 'wrong', 'brusque', 'vermont', 'packets', \"she's\", 'grubby', 'gotcha', 'terrible', 'remorseful', 'gordon', 'tries', 'doy', 'germany', 'incredible', \"wouldn't\", 'lard', 'powers', 'rough', 'threatening', 'taunting', 'disdainful', 'tremendous', 'expression', 'repairman', 'lindsay', 'britannia', \"mcstagger's\", 'frankie', 'massachusetts', 'bumpy-like', 'traitors', 'eco-fraud', 'africanized', 'wire', 'c', 'wheeeee', 'dying', 'met', 'its', 'focused', 'relaxing', 'queer', 'helped', 'fastest', 'bones', 'nemo', 'sister-in-law', 'dogs', 'fever', 'person', 'annoyed', 'perfume', 'lemonade', 'repay', 'meaningfully', 'soft', 'home', 'wolverines', 'holy', 'winner', 'burg', 'same', 'phone', 'choking', 'why', 'yards', 'nelson', 'birthplace', 'pickles', 'girl-bart', 'tried', 'using', 'damned', 'cobbling', 'dinks', 'skeptical', 'hubub', 'bake', 'twenty-two', 'online', 'thoughtful', 'flaking', 'cherry', 'obsessive-compulsive', 'stools', 'gator:', 'initially', 'jacksons', 'boat', 'hit', 'talkers', 'jacques:', 'island', 'woman_bystander:', 'rocks', 'flame', 'domestic', 'back', 'black', 'infestation', 'pen', 'marmaduke', \"smokin'_joe_frazier:\", 'painless', 'haiti', 'knocks', 'ambrose', 'liar', 'because', 'unexplained', 'hoo', 'menace', 'admitting', 'dizer', 'grunts', 'stein-stengel-', 'roses', 'fights', 'snatch', 'moe_recording:', 'rainier_wolfcastle:', 'sneak', \"leavin'\", 'button-pusher', 'attractive_woman_#2:', 'cheaper', 'hourly', 'detail', 'excitement', 'harrowing', 'jigger', 'thinking', 'democracy', 'applesauce', 'outstanding', 'thawing', 'pus-bucket', 'source', 'raises', 'mirthless', 'crappy', 'built', 'compromise:', 'turns', 'prompting', 'dumptruck', 'telemarketing', 'correcting', 'soaking', 'groin', 'deep', 'nicer', 'wheel', 'sounds', 'corner', 'mags', 'know', \"payin'\", 'yourself', 'both', 'jogging', 'anguished', 'sober', 'reading:', 'ninety-nine', 'mustard', 'shack', 'renovations', 'frontrunner', 'hammock', \"treatin'\", 'hoped', 'wondering', 'dear', 'smiling', 'watered-down', 'occupation', \"tv's\", \"wallet's\", 'taxes', 'idiots', 'cyrano', 'buddha', 'son-of-a', 'loves', 'overhearing', 'pages', 'who-o-oa', 'carl:', 'bridges', 'archaeologist', \"d'\", 'simple', 'lowest', 'deacon', 'fly', 'reserved', 'glen:', 'barstools', \"lefty's\", 'social', 'novel', 'businessman_#2:', 'chastity', 'hare-brained', 'champ', 'clone', 'means', 'side', 'voodoo', 'toss', 'pulitzer', 'makes', 'quero', 'streetlights', 'whip', 'paste', 'grienke', 'bury', 'wayne', \"lady's\", 'stores', 'walking', \"patrick's\", 'washouts', 'appreciated', 'fainted', 'burns', 'wildest', 'tigers', 'lips', 'ding-a-ding-ding-a-ding-ding', \"fishin'\", 'men', 'tin', 'homer', 'officials', 'lewis', 'women', 'suspended', 'jumps', 'dough', 'stripes', 'frustrated', 'stewart', 'marquee', 'six-barrel', 'house', 'awed', 'delightfully', 'affection', 'lives', 'starting', 'darkness', 'leak', 'bridge', 'beef', 'travel', 'cheerleaders:', 'swe-ee-ee-ee-eet', 'scores', 'blowfish', 'legoland', \"shan't\", 'loan', 'ground', 'mona_simpson:', 'lighten', 'kang:', \"countin'\", 'mike_mills:', 'stengel', 'sold', 'bonding', 'honor', 'okay', '6', \"we've\", 'masks', 'began', 'marge', \"'em\", \"duelin'\", 'emotional', 'shyly', 'jam', 'k-zug', 'pridesters:', 'gorgeous', 'exchanged', 'outs', 'shaker', 'radical', 'calling', 'expert', 'those', 'beer', 'listens', 'truck_driver:', 'snide', 'introduce', 'title:', 'everything', 'value', 'all:', 'open', 'bartender', 'successful', 'learn', 'sports', 'warmly', 'mindless', 'prettied', 'fist', 'bide', 'linda', 'pour', 'rush', 'compels', 'vacation', 'being', 'lurks', 'sanctuary', 'choice', 'chapstick', 'marriage', 'muslim', 'hello', 'naegle', 'inspector', 'scarf', 'closed', 'fuhgetaboutit', 'flynt', 'disco_stu:', 'sheet', 'when', 'exciting', \"sippin'\", 'zoomed', 'dreamily', 'ohmygod', 'jerky', 'till', 'scotch', 'spooky', 'emotion', 'program', 'grunt', 'restaurant', 'crime', 'gig', 'yew', 'ointment', 'knock-up', 'stalwart', 'nailed', 'little', 'duke', 'balloon', 'deserve', \"'bout\", \"they're\", 'problem', 'medical', 'half-back', 'comes', 'gesture', 'burn', 'bump', 'repressed', 'busted', 'co-sign', 'hampstead-on-cecil-cecil', 'name', 'we-we-we', 'shares', 'amanda', 'snotty', 'mcclure', 'broom', 'brainiac', 'duff_announcer:', 'bathed', 'drawer', 'throws', 'dumpster', 'pats', 'bird', \"city's\", 'speed', 'alive', 'believer', 'decide:', 'north', 'depending', 'mamma', 'effect', 'nods', 'flourish', 'park', 'roof', 'griffith', 'mulder', 'wrote', 'bubbles', 'falling', 'mill', 'relax', 'deer', 'rebuilt', 'researching', 'ons', 'ahhhh', 'blimp', 'penny', 'awareness', 'mccall', \"'now\", 'brooklyn', 'ooh', 'pretending', 'now', 'shoulda', 'roll', 'greetings', 'motto', 'bitter', 'naively', 'attack', 'everyday', 'gosh', 'killarney', 'wonder', 'charge', 'sandwich', 'lifestyle', 'dangerous', 'election', 'carny:', 'arise', 'anyhow', 'caholic', \"smokin'\", 'pigs', 'nectar', 'clap', 'eggs', 'conspiracy', 'voice:', 'trashed', 'frat', 'completely', 'absentmindedly', 'craphole', 'heavyset', 'conversation', 'handle', 'talk', 'poke', 'viva', 'hellhole', 'whirlybird', 'octa-', 'pilsner-pusher', 'sick', 'tastes', 'attracted', 'we', 'lloyd', 'mirror', 'rivalry', 'wide', 'edna_krabappel-flanders:', 'youth', 'boggs', 'payback', 'ummmmmmmmm', 'patrons:', 'merchants', 'wind', 'mccarthy', 'ahh', 'making', \"nixon's\", 'published', '/', 'really', 'aghast', 'rosey', 'traitor', 'puff', 'waterfront', 'verticality', 'short', 'placing', 'pawed', 'busy', 'trying', 'senators', 'yawns', 'connor-politan', 'planning', 'pool', 'pure', \"hasn't\", 'h', 'although', 'droning', 'easily', 'raining', 'literary', 'agh', 'managed', \"she'll\", 'lear', 'evil', '&', 'risqu茅', 'distinct', 'transylvania', 'truth', \"queen's\", 'inspiring', 'gunter:', 'practice', 'panicky', 'belches', 'shock', '_montgomery_burns:', 'operation', 'krusty', 'dint', 'refill', 'care', 'eyesore', 'blinded', \"floatin'\", 'pernt', 'omigod', 'maude', 'bugs', 'blackjack', 'ugliest', 'resigned', 'blame', 'pressure', 'worth', \"'im\", \"bettin'\", 'seriously', 'lovers', \"jimbo's_dad:\", 'punches', 'charges', 'i-i-i', 'treats', 'meals', 'nature', 'touchdown', 'see', 'crony', 'stepped', 'finishing', 'occurs', 'admiring', 'fanciest', 'reason', 'ever', 'muttering', \"won't\", 'neighboreeno', 'look', 'frenchman', 'term', 'behavior', 'louisiana', 'crimes', 'blank', 'unbelievably', 'art', 'roach', 'paid', 'news', 'rice', 'three', 'whup', 'worked', 'united', 'anti-crime', 'cut', 'befriend', 'driver', 'jamaican', 'horribilis', 'noooooooooo', 'trapped', 'wants', 'intense', 'present', 'however', 'michael', 'november', 'engraved', 'padres', 'yelling', 'anderson', 'fail', 'luckily', 'cummerbund', 'dracula', 'saint', 'challenge', 'yelp', 'wiggle-frowns', 'beings', 'gulps', 'and', 'crowbar', 'double', 'tsk', 'instrument', 'director', 'astronauts', 'chicken', 'pre-columbian', 'buy', 'store', 'belch', 'across', 'weirded-out', 'mini-beret', 'into', 'unearth', 'shipment', 'trucks', 'inanely', 'patting', 'crayon', 'cauliflower', \"i'd'a\", 'fault', 'explain', 'cell-ee', 'roller', 'jerk', 'runaway', 'gals', 'ing', 'extreme', 'donut', 'wanted', 'shifty', 'sarcastic', 'unsanitary', 'data', 'loaded', 'would', 'miserable', 'browns', 'lone', 'set', 'promise', 'displeased', 'service', 'fancy', 'circus', 'intakes', 'beats', 'prepared', 'overflowing', 's-a-u-r-c-e', 'ashamed', 'undies', 'earpiece', \"stallin'\", 'carlotta:', 'drummer', \"carl's\", 'hugh', 'soir', 'remembered', 'billboard', 'craft', 'foodie', 'situation', 'obama', 'bindle', 'forgets', 'celebrate', 'ehhhhhh', 'make', 'chief_wiggum:', 'dentist', 'cotton', 'night-crawlers', \"g'night\", 'revenge', 'all-american', 'betcha', \"brockman's\", 'hair', 'eyeing', 'ralph_wiggum:', 'around', 'onion', 'punk', 'pass', 'pillows', 'carefully', 'jimmy', 'mr', 'somebody', '1895', 'slim', 'bash', 'sap', 'scanning', 'necessary', 'macbeth', 'accounta', 'grrrreetings', 'white_rabbit:', 'looooooooooooooooooong', 'issues', 'reopen', 'taking', '35', 'amount', 'brothers', 'carnival', 'found', 'zero', 'canyonero', 'sharing', 'stained-glass', 'rolls', 'female_inspector:', 'god', 'bits', 'basement', 'koji', 'bobo', 'romantic', 'blows', 'pointedly', 'picture', 'lifts', 'facebook', 'haikus', 'single', 'fringe', 'reaching', 'washer', 'encores', 'nameless', 'bob', 'kegs', 'goodnight', 'some', 'doom', 'faceful', \"speakin'\", 'noose', 'ginger', 'rich', 'avalanche', 'example', 'wallet', 'owes', 'threw', \"it's\", 'dice', 'homunculus', 'forget', 'amid', 'cutie', 'dad', 'bike', 'every', 'warning', 'wenceslas', 'chinese_restaurateur:', 'stonewall', 'billingsley', 'understand', 'image', 'hanging', 'lap', 'control', 'chill', 'eaters', 'ironic', 'blaze', 'generously', \"secret's\", 'past', 'record', 'backing', 'were', 'jewish', 'gruesome', 'invited', 'juice', 'hole', 'clothes', 'sixty', 'liable', 'twenty-four', \"summer's\", 'bell', 'fabulous', 'nagurski', \"scammin'\", 'christopher', 'notices', 'scoffs', 'savings', 'impressed', 'you', ':', 'blocked', 'boxing_announcer:', \"lisa's\", 'held', 'case', 'marshmallow', 'reliable', \"doesn't\", 'banquet', 'wok', '||return||', 'hmm', 'cooker', 'sneaky', 'fulla', 'lance', 'watt', 'teddy', 'club', 'dramatic', 'whee', 'oils', 'ho', 'micronesian', 'group', 'dunno', 'yoo', 'specific', 'spine', 'agent_johnson:', 'represents', 'understanding', 'suave', 'so', 'skinny', 'fritz:', 'lonely', 'magazine', 'shades', 'marvin', 'simplest', 'eggshell', 'grampa_simpson:', 'tree', 'mortal', 'ingested', 'going', 'repeating', 'peace', 'alien', 'rekindle', 'blamed', 'wrestling', '530', 'cheese', 'wolfcastle', 'quick', 'eddie:', 'o', 'regretted', 'costume', 'taught', 'pretends', 'ways', 'physical', 'disco', 'knowing', 'media', 'ecru', 'solid', 'pizzicato', 'authenticity', 'kill', \"raggin'\", 'spend', 'painted', 'loathe', 'wise', 'crumble', 'witches', 'body', 'inspection', 'worse', 'pretty', 'thru', \"department's\", 'street', 'liquor', 'habit', 'mafia', 'talking', \"aren't\", 'braun:', 'enabling', 'hike', 'kearney_zzyzwicz:', 'booger', 'fictional', 'meeting', 'mailbox', 'afternoon', 'court', 'photographer', 'depressing', 'experience', 'lushmore', 'game', \"who's\", 'consulting', 'vomit', 'pardon', 'noticing', 'each', 'uncreeped-out', 'pushes', 'rem', 'tail', 'diminish', 's', 'clear', 'turned', 'heliotrope', 'staying', 'under', 'went', 'low-life', 'investor', 'devastated', 'undermine', 'mckinley', 'courteous', 'committing', 'scare', 'adeleine', 'awfully', 'done', 'second', 'tomahto', 'disapproving', 'youse', 'gargoyles', 'sniffing', 'hmmm', 'bluff', 'sympathy', 'tradition', 'says', 'wave', 'pretend', 'roz', 'science', 'credit', 'sit', 'evasive', 'increasingly', 'errrrrrr', 'level', 'malabar', 'quick-like', 'doubt', 'meet', 'bulldozing', 'strap', 'kansas', 'chosen', 'pursue', 'blue', 'sips', 'der', 'contemporary', 'strategy', 'engine', 'driveability', \"tramp's\", 'radioactive', 'how', \"'kay-zugg'\", 'grumpy', 'caveman', 'guessing', 'ehhhhhhhh', '||exclamationmark||', 'fwooof', 'few', 'glitz', 'grand茅', 'cameras', 'stamps', 'nearly', 'innocuous', 'gasoline', 'suds', 'boyhood', 'du', 'reality', 'recorder', 'perfect', 'living', \"drexel's\", 'ron_howard:', 'cats', 'newsies', 'excuses', 'dryer', 'gibson', 'fox', 'sumatran', 'teriyaki', 'cuz', 'hillbillies', 'beam', 'idea', 'steal', 'cleveland', 'run', 'ivana', 'denser', 'donation', 'belt', \"year's\", 'blind', 'orders', 'hooch', 'i-i', 'created', 'according', 'civil', 'dimly', 'offense', 'estranged', 'scream', 'plotz', 'become', 'minister', 'spinning', 'eager', 'ease', 'scary', 'law', 'goo', 'blow', 'placed', 'names', 'road', 'awww', 'moving', 'dan', 'kids', 'weekly', 'row', \"don't\", 'awful', 'recap:', 'arimasen', 'detecting', 'has', 'sassy', 'patty_bouvier:', 'surprised/thrilled', 'doll', 'scientists', 'die-hard', 'harvey', 'up-bup-bup', 'haircuts', 'seat', 'author', 'fill', 'poking', 'excited', 'elder', 'wakede'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(data_dir, token_lookup, create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import helper\n",
    "import numpy as np\n",
    "import problem_unittests as tests\n",
    "\n",
    "int_text, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Neural Network\n",
    "You'll build the components necessary to build a RNN by implementing the following functions below:\n",
    "- get_inputs\n",
    "- get_init_cell\n",
    "- get_embed\n",
    "- build_rnn\n",
    "- build_nn\n",
    "- get_batches\n",
    "\n",
    "### Check the Version of TensorFlow and Access to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.8.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer'\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input\n",
    "Implement the `get_inputs()` function to create TF Placeholders for the Neural Network.  It should create the following placeholders:\n",
    "- Input text placeholder named \"input\" using the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) `name` parameter.\n",
    "- Targets placeholder\n",
    "- Learning Rate placeholder\n",
    "\n",
    "Return the placeholders in the following tuple `(Input, Targets, LearningRate)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_inputs():\n",
    "    \"\"\"\n",
    "    Create TF Placeholders for input, targets, and learning rate.\n",
    "    :return: Tuple (input, targets, learning rate)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    input_ =  tf.placeholder(tf.int32,name=\"input\",shape=(None,None))\n",
    "    target_ = tf.placeholder(tf.int32,name=\"target\",shape=(None,None))\n",
    "    learning_rate_ = tf.placeholder(tf.float32,name=\"learning_rate\",shape=(None))\n",
    "    return input_, target_, learning_rate_\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_inputs(get_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build RNN Cell and Initialize\n",
    "Stack one or more [`BasicLSTMCells`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell) in a [`MultiRNNCell`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/MultiRNNCell).\n",
    "- The Rnn size should be set using `rnn_size`\n",
    "- Initalize Cell State using the MultiRNNCell's [`zero_state()`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/MultiRNNCell#zero_state) function\n",
    "    - Apply the name \"initial_state\" to the initial state using [`tf.identity()`](https://www.tensorflow.org/api_docs/python/tf/identity)\n",
    "\n",
    "Return the cell and initial state in the following tuple `(Cell, InitialState)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_init_cell(batch_size, rnn_size):\n",
    "    \"\"\"\n",
    "    Create an RNN Cell and initialize it.\n",
    "    :param batch_size: Size of batches\n",
    "    :param rnn_size: Size of RNNs\n",
    "    :return: Tuple (cell, initialize state)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    # basic LSTM cell\n",
    "    def make_lstm(rnn_size):\n",
    "        return tf.contrib.rnn.BasicLSTMCell(rnn_size, state_is_tuple=True, reuse=tf.get_variable_scope().reuse)\n",
    "    #LSTM cell\n",
    "    #lstm = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
    "    #drop = tf.contrib.rnn.DropoutWrapper(lstm)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([make_lstm(rnn_size) for _ in range(2)], state_is_tuple=True)\n",
    "    #initial state\n",
    "    #assert type(batch_size) == 'int', 'batch_size is not a tensor'\n",
    "    # initial_state = cell.zero_state(batch_size, tf.float32)#第一个参数不接受tensor\n",
    "    initial_state = cell.zero_state(64, tf.float32)\n",
    "    \n",
    "    # tf.identity属于tensorflow中的一个ops，跟x = x + 0.0的性质一样，返回一个tensor，\n",
    "    # 受到tf.control_dependencies的约束，所以生效。\n",
    "    initial_state = tf.identity(initial_state,name='initial_state')\n",
    "    return cell, initial_state\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_init_cell(get_init_cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding\n",
    "Apply embedding to `input_data` using TensorFlow.  Return the embedded sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_embed(input_data, vocab_size, embed_dim):\n",
    "    \"\"\"\n",
    "    Create embedding for <input_data>.\n",
    "    :param input_data: TF placeholder for text input.\n",
    "    :param vocab_size: Number of words in vocabulary.\n",
    "    :param embed_dim: Number of embedding dimensions\n",
    "    :return: Embedded input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #embedding = tf.Variable(tf.random_uniform((vocab_size, embed_dim)), dtype=tf.float32)\n",
    "    #inputs = tf.nn.embedding_lookup(embedding, input_data)\n",
    "    inputs = tf.contrib.layers.embed_sequence(input_data,vocab_size,embed_dim)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_embed(get_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build RNN\n",
    "You created a RNN Cell in the `get_init_cell()` function.  Time to use the cell to create a RNN.\n",
    "- Build the RNN using the [`tf.nn.dynamic_rnn()`](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn)\n",
    " - Apply the name \"final_state\" to the final state using [`tf.identity()`](https://www.tensorflow.org/api_docs/python/tf/identity)\n",
    "\n",
    "Return the outputs and final_state state in the following tuple `(Outputs, FinalState)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def build_rnn(cell, inputs):\n",
    "    \"\"\"\n",
    "    Create a RNN using a RNN Cell\n",
    "    :param cell: RNN Cell\n",
    "    :param inputs: Input text data\n",
    "    :return: Tuple (Outputs, Final State)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell, inputs,dtype=tf.float32)\n",
    "    final_state = tf.identity(final_state, name='final_state')\n",
    "    return outputs, final_state\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_build_rnn(build_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Neural Network\n",
    "Apply the functions you implemented above to:\n",
    "- Apply embedding to `input_data` using your `get_embed(input_data, vocab_size, embed_dim)` function.\n",
    "- Build RNN using `cell` and your `build_rnn(cell, inputs)` function.\n",
    "- Apply a fully connected layer with a linear activation and `vocab_size` as the number of outputs.\n",
    "\n",
    "Return the logits and final state in the following tuple (Logits, FinalState) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def build_nn(cell, rnn_size, input_data, vocab_size, embed_dim):\n",
    "    \"\"\"\n",
    "    Build part of the neural network\n",
    "    :param cell: RNN cell\n",
    "    :param rnn_size: Size of rnns\n",
    "    :param input_data: Input data\n",
    "    :param vocab_size: Vocabulary size\n",
    "    :param embed_dim: Number of embedding dimensions\n",
    "    :return: Tuple (Logits, FinalState)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    inputs = get_embed(input_data, vocab_size, embed_dim)\n",
    "    outputs, final_state = build_rnn(cell, inputs)\n",
    "    logits = tf.contrib.layers.fully_connected(outputs, vocab_size,activation_fn=None)\n",
    "    return logits, final_state\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_build_nn(build_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batches\n",
    "Implement `get_batches` to create batches of input and targets using `int_text`.  The batches should be a Numpy array with the shape `(number of batches, 2, batch size, sequence length)`. Each batch contains two elements:\n",
    "- The first element is a single batch of **input** with the shape `[batch size, sequence length]`\n",
    "- The second element is a single batch of **targets** with the shape `[batch size, sequence length]`\n",
    "\n",
    "If you can't fill the last batch with enough data, drop the last batch.\n",
    "\n",
    "For exmple, `get_batches([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 2, 3)` would return a Numpy array of the following:\n",
    "```\n",
    "[\n",
    "  # First Batch\n",
    "  [\n",
    "    # Batch of Input\n",
    "    [[ 1  2  3], [ 7  8  9]],\n",
    "    # Batch of targets\n",
    "    [[ 2  3  4], [ 8  9 10]]\n",
    "  ],\n",
    " \n",
    "  # Second Batch\n",
    "  [\n",
    "    # Batch of Input\n",
    "    [[ 4  5  6], [10 11 12]],\n",
    "    # Batch of targets\n",
    "    [[ 5  6  7], [11 12 13]]\n",
    "  ]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_batches(int_text, batch_size, seq_length):\n",
    "    \"\"\"\n",
    "    Return batches of input and target\n",
    "    :param int_text: Text with the words replaced by their ids\n",
    "    :param batch_size: The size of batch\n",
    "    :param seq_length: The length of sequence\n",
    "    :return: Batches as a Numpy array\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    n_batches = len(int_text) // (batch_size * seq_length)\n",
    "    batches_ = []\n",
    "    for i in range(0, n_batches):\n",
    "        input_batch = []\n",
    "        target_batch = []\n",
    "        for j in range(0, batch_size):\n",
    "            #input_i = i * batch_size * seq_length + j * seq_length\n",
    "            input_i = i * seq_length + j * seq_length * n_batches\n",
    "            target_i = input_i + 1\n",
    "            input_ = int_text[input_i:input_i + seq_length]\n",
    "            target_ = int_text[target_i:target_i + seq_length]\n",
    "            input_batch.append(input_)\n",
    "            target_batch.append(target_)\n",
    "        batches_.append([input_batch, target_batch])\n",
    "        \n",
    "    return np.array(batches_)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_batches(get_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Training\n",
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "\n",
    "- Set `num_epochs` to the number of epochs.\n",
    "- Set `batch_size` to the batch size.\n",
    "- Set `rnn_size` to the size of the RNNs.\n",
    "- Set `embed_dim` to the size of the embedding.\n",
    "- Set `seq_length` to the length of sequence.\n",
    "- Set `learning_rate` to the learning rate.\n",
    "- Set `show_every_n_batches` to the number of batches the neural network should print progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Epochs\n",
    "num_epochs = 5\n",
    "# Batch Size\n",
    "batch_size = 64\n",
    "# RNN Size\n",
    "rnn_size = 256\n",
    "# Embedding Dimension Size\n",
    "embed_dim = 300\n",
    "# Sequence Length\n",
    "seq_length = 12\n",
    "# Learning Rate\n",
    "learning_rate = 0.005\n",
    "# Show stats for every n number of batches\n",
    "show_every_n_batches = 10\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "save_dir = './save'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Graph\n",
    "Build the graph using the neural network you implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "from tensorflow.contrib import seq2seq\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    vocab_size = len(int_to_vocab)\n",
    "    input_text, targets, lr = get_inputs()\n",
    "    input_data_shape = tf.shape(input_text)\n",
    "    cell, initial_state = get_init_cell(input_data_shape[0], rnn_size)\n",
    "    logits, final_state = build_nn(cell, rnn_size, input_text, vocab_size, embed_dim)\n",
    "\n",
    "    # Probabilities for generating words\n",
    "    probs = tf.nn.softmax(logits, name='probs')\n",
    "\n",
    "    # Loss function\n",
    "    cost = seq2seq.sequence_loss(\n",
    "        logits,\n",
    "        targets,\n",
    "        tf.ones([input_data_shape[0], input_data_shape[1]]))\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "    # Gradient Clipping\n",
    "    gradients = optimizer.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "    train_op = optimizer.apply_gradients(capped_gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "Train the neural network on the preprocessed data.  If you have a hard time getting a good loss, check the [forms](https://discussions.udacity.com/) to see if anyone is having the same problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch    0/89   train_loss = 8.822\n",
      "Epoch   0 Batch   10/89   train_loss = 6.698\n",
      "Epoch   0 Batch   20/89   train_loss = 6.797\n",
      "Epoch   0 Batch   30/89   train_loss = 7.008\n",
      "Epoch   0 Batch   40/89   train_loss = 6.506\n",
      "Epoch   0 Batch   50/89   train_loss = 6.444\n",
      "Epoch   0 Batch   60/89   train_loss = 6.709\n",
      "Epoch   0 Batch   70/89   train_loss = 6.336\n",
      "Epoch   0 Batch   80/89   train_loss = 6.779\n",
      "Epoch   1 Batch    1/89   train_loss = 6.262\n",
      "Epoch   1 Batch   11/89   train_loss = 6.328\n",
      "Epoch   1 Batch   21/89   train_loss = 5.945\n",
      "Epoch   1 Batch   31/89   train_loss = 6.288\n",
      "Epoch   1 Batch   41/89   train_loss = 6.061\n",
      "Epoch   1 Batch   51/89   train_loss = 6.267\n",
      "Epoch   1 Batch   61/89   train_loss = 6.306\n",
      "Epoch   1 Batch   71/89   train_loss = 6.024\n",
      "Epoch   1 Batch   81/89   train_loss = 6.060\n",
      "Epoch   2 Batch    2/89   train_loss = 5.809\n",
      "Epoch   2 Batch   12/89   train_loss = 5.651\n",
      "Epoch   2 Batch   22/89   train_loss = 5.668\n",
      "Epoch   2 Batch   32/89   train_loss = 5.497\n",
      "Epoch   2 Batch   42/89   train_loss = 5.614\n",
      "Epoch   2 Batch   52/89   train_loss = 5.483\n",
      "Epoch   2 Batch   62/89   train_loss = 5.501\n",
      "Epoch   2 Batch   72/89   train_loss = 5.588\n",
      "Epoch   2 Batch   82/89   train_loss = 5.383\n",
      "Epoch   3 Batch    3/89   train_loss = 5.316\n",
      "Epoch   3 Batch   13/89   train_loss = 5.180\n",
      "Epoch   3 Batch   23/89   train_loss = 5.367\n",
      "Epoch   3 Batch   33/89   train_loss = 5.109\n",
      "Epoch   3 Batch   43/89   train_loss = 5.235\n",
      "Epoch   3 Batch   53/89   train_loss = 5.314\n",
      "Epoch   3 Batch   63/89   train_loss = 4.975\n",
      "Epoch   3 Batch   73/89   train_loss = 4.947\n",
      "Epoch   3 Batch   83/89   train_loss = 5.231\n",
      "Epoch   4 Batch    4/89   train_loss = 5.060\n",
      "Epoch   4 Batch   14/89   train_loss = 4.656\n",
      "Epoch   4 Batch   24/89   train_loss = 4.871\n",
      "Epoch   4 Batch   34/89   train_loss = 4.860\n",
      "Epoch   4 Batch   44/89   train_loss = 4.880\n",
      "Epoch   4 Batch   54/89   train_loss = 4.893\n",
      "Epoch   4 Batch   64/89   train_loss = 4.891\n",
      "Epoch   4 Batch   74/89   train_loss = 4.755\n",
      "Epoch   4 Batch   84/89   train_loss = 4.610\n",
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "batches = get_batches(int_text, batch_size, seq_length)\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch_i in range(num_epochs):\n",
    "        state = sess.run(initial_state, {input_text: batches[0][0]})\n",
    "\n",
    "        for batch_i, (x, y) in enumerate(batches):\n",
    "            feed = {\n",
    "                input_text: x,\n",
    "                targets: y,\n",
    "                initial_state: state,\n",
    "                lr: learning_rate}\n",
    "            train_loss, state, _ = sess.run([cost, final_state, train_op], feed)\n",
    "\n",
    "            # Show every <show_every_n_batches> batches\n",
    "            if (epoch_i * len(batches) + batch_i) % show_every_n_batches == 0:\n",
    "                print('Epoch {:>3} Batch {:>4}/{}   train_loss = {:.3f}'.format(\n",
    "                    epoch_i,\n",
    "                    batch_i,\n",
    "                    len(batches),\n",
    "                    train_loss))\n",
    "\n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, save_dir)\n",
    "    print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Parameters\n",
    "Save `seq_length` and `save_dir` for generating a new TV script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Save parameters for checkpoint\n",
    "helper.save_params((seq_length, save_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import helper\n",
    "import problem_unittests as tests\n",
    "\n",
    "_, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()\n",
    "seq_length, load_dir = helper.load_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Generate Functions\n",
    "### Get Tensors\n",
    "Get tensors from `loaded_graph` using the function [`get_tensor_by_name()`](https://www.tensorflow.org/api_docs/python/tf/Graph#get_tensor_by_name).  Get the tensors using the following names:\n",
    "- \"input:0\"\n",
    "- \"initial_state:0\"\n",
    "- \"final_state:0\"\n",
    "- \"probs:0\"\n",
    "\n",
    "Return the tensors in the following tuple `(InputTensor, InitialStateTensor, FinalStateTensor, ProbsTensor)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_tensors(loaded_graph):\n",
    "    \"\"\"\n",
    "    Get input, initial state, final state, and probabilities tensor from <loaded_graph>\n",
    "    :param loaded_graph: TensorFlow graph loaded from file\n",
    "    :return: Tuple (InputTensor, InitialStateTensor, FinalStateTensor, ProbsTensor)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    input_ = loaded_graph.get_tensor_by_name('input:0')\n",
    "    initial_state_ = loaded_graph.get_tensor_by_name('initial_state:0')\n",
    "    final_state_ = loaded_graph.get_tensor_by_name('final_state:0')\n",
    "    probs_ = loaded_graph.get_tensor_by_name('probs:0')\n",
    "    return input_, initial_state_, final_state_, probs_\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_tensors(get_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Word\n",
    "Implement the `pick_word()` function to select the next word using `probabilities`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def pick_word(probabilities, int_to_vocab):\n",
    "    \"\"\"\n",
    "    Pick the next word in the generated text\n",
    "    :param probabilities: Probabilites of the next word\n",
    "    :param int_to_vocab: Dictionary of word ids as the keys and words as the values\n",
    "    :return: String of the predicted word\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    #index_ = np.where(probabilities == np.max(probabilities))[0][0]\n",
    "    return np.random.choice(list(int_to_vocab.values()), 1, p=probabilities)[0]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_pick_word(pick_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate TV Script\n",
    "This will generate the TV script for you.  Set `gen_length` to the length of TV script you want to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "object too deep for desired array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-afac68e7c099>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mprobabilities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprev_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_state\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0minput_text\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdyn_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprev_state\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m#         print('probabilities last', probabilities[dyn_seq_length-1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mpred_word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpick_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdyn_seq_length\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint_to_vocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mgen_sentences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-bf57c4dccca5>\u001b[0m in \u001b[0;36mpick_word\u001b[1;34m(probabilities, int_to_vocab)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# TODO: Implement Function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#index_ = np.where(probabilities == np.max(probabilities))[0][0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint_to_vocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: object too deep for desired array"
     ]
    }
   ],
   "source": [
    "gen_length = 200\n",
    "# homer_simpson, moe_szyslak, or Barney_Gumble\n",
    "prime_word = 'moe_szyslak'\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
    "    loader.restore(sess, load_dir)\n",
    "\n",
    "    # Get Tensors from loaded model\n",
    "    input_text, initial_state, final_state, probs = get_tensors(loaded_graph)\n",
    "\n",
    "    # Sentences generation setup\n",
    "    gen_sentences = [prime_word + ':']\n",
    "    prev_state = sess.run(initial_state, {input_text: np.array([[1]])})\n",
    "\n",
    "    # Generate sentences\n",
    "    for n in range(gen_length):\n",
    "        # Dynamic Input\n",
    "        dyn_input = [[vocab_to_int[word] for word in gen_sentences[-seq_length:]]]\n",
    "        dyn_seq_length = len(dyn_input[0])\n",
    "\n",
    "        # Get Prediction\n",
    "        probabilities, prev_state = sess.run(\n",
    "            [probs, final_state],\n",
    "            {input_text: dyn_input, initial_state: prev_state})\n",
    "#         print('probabilities last', probabilities[dyn_seq_length-1])\n",
    "        pred_word = pick_word(probabilities[dyn_seq_length-1], int_to_vocab)\n",
    "\n",
    "        gen_sentences.append(pred_word)\n",
    "    \n",
    "    # Remove tokens\n",
    "    tv_script = ' '.join(gen_sentences)\n",
    "    for key, token in token_dict.items():\n",
    "        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
    "        tv_script = tv_script.replace(' ' + token.lower(), key)\n",
    "    tv_script = tv_script.replace('\\n ', '\\n')\n",
    "    tv_script = tv_script.replace('( ', '(')\n",
    "        \n",
    "    print(tv_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The TV Script is Nonsensical\n",
    "It's ok if the TV script doesn't make any sense.  We trained on less than a megabyte of text.  In order to get good results, you'll have to use a smaller vocabulary or get more data.  Luckly there's more data!  As we mentioned in the begging of this project, this is a subset of [another dataset](https://www.kaggle.com/wcukierski/the-simpsons-by-the-data).  We didn't have you train on all the data, because that would take too long.  However, you are free to train your neural network on all the data.  After you complete the project, of course.\n",
    "# Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as \"dlnd_tv_script_generation.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\". Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
